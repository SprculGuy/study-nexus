AWS is a cloud provider(like Microsoft Azure, GCP) which provides you with services and servers that you can use on demand and scale easily
    some of the biggest websites hosted on AWS 
        1. amazon.com
        2. netflix  


AWS Cloud History -
    2002 - internally launched
    2004 - publicly launched SQS(simple queue services)
    2006 - relaunched publicly SQS, S3, EC2



Shared Responsibility Model
    AWS Cloud Responsibility - Security of the Cloud
        - Infrastructure(Global Network(data centers) Security) - patching and fixing flaws within the infrastructure
        - Isolation on physical hosts(for dedicated hosts)
        - Replacing faulty hardware, OS maintenance/patching,, Optimizations, Backup & Replication for managed services like, S3, dynamodb, RDS, etc.
        - compliance validation(regulations)
 
    Users/Customer Responsibility - Security in the Cloud
        - Security Groups rules, firewall & network configuration
        - Guest OS, application patches and updates of software & utilities installed
        - IAM roles assignment & user access management
        - Encryption of application data(client-side as well as server-side)
        - data Backup(snapshot) & Replication procedure

	Shared Responsibility - 
		- Patch Management
		- Configuration Management
		- Awareness & Training



Ideal AWS Application Architectures;
	1. Stateless Server Architectures; Stateless : Store session data(ElastiCache, RDS, Client HTTP cookies)
										Multi-AZ and Health Checks enabled				  Multi-AZ ASG
		Route 53 	<-- 	User   -->	  	  Elastic Load Balancer				-->		AZ1-EC2, AZ2-EC2,...



	2. Statefull Server Architectures											
																										  Multi-AZ				   Multi-AZ
																										 ElastiCache	 	-->		  RDS
				    																		  ↱			Lazy Loading			  Read Replicas	 		
				    							Multi-AZ					Multi-AZ ASG	  |	   		(res caching)
		Route 53    <-- 	User   	-->	  Elastic Load Balancer		-->			EC2 		--|	  
				    	 Session ID			 Health Checks						ENI			  |	  	  
																							  ↳				EFS



	3. Microservice Architecture
									↗↙------>  API Gateway  <------>  Lambda  <------>  ElastiCache
								  ↗↙					 ↖↘
		Route 53  <-->	Users  <---- HTTPS ----->  ELB <--> ECS  <------>  DynamoDB
								  ↘↖				 ↖↘
								  	↘↖--->  ELB  <-->  EC2  <------>  RDS



	4. Serverless Architectures
			 			 Authenticate
				 	    ↗↙----------------<->  Cognito
				     ↗↙Temp IAM permission 	  	  ⬆
				   ↗↙For partial S3 access		  |Auth Verify
				 ↗↙     						  ⬇
			Client    <--- REST HTTPS --->    API Gateway    <--- Invoke --->    Lambda    <--- Query/read --->    DAX <----> DynamoDB <--Event--> Lambda --> SES
			⬇⬆	 ↘↖				   			   Caching															 Caching 
	Temp IAM⬇⬆     ↘↖
  Permissions↘↖     ↘↖
		 	   S3	   CloudFront Global    <--- OAC --->    S3
		  Cloud Storage									   Static
		    for user↘↖									  Content
					  ↘↖
						Lambda	---->  S3
					  Thumbnails


																					VPC
																Public Subnets					Private Subnet
																Security Group 				   
			AWS Shield		   			AWS Shield				  AWS Shield			  		Security Group	
			Route 53 <-- User --> CloudFront Distribution  -->   Load Balancer		-->       Auto Scaling Group    -->    Application(EC2 instances, DB, etc.)
											⇣⇡						  ⇣⇡	
										 AWS WAF					 ACM

		Additional Best Practices
			Monitoring and Logging:
				CloudWatch: For monitoring and logging.
				CloudTrail: For auditing API calls.
			Backup and Recovery:
				AWS Backup: Centralized backup service.
				RDS Automated Backups: For database backups.
			Security:
				AWS KMS (Key Management Service): For managing encryption keys.
				AWS Secrets Manager: For managing secrets like database credentials.
			Networking:
				VPC Peering: For connecting VPCs.
				Transit Gateway: For connecting multiple VPCs and on-premises networks.



Note - Serverless doesn't mean absence of servers but it means the developers don’t have to manage servers anymore, developers only need to deploy code/functions



AWS Services
	Account Management 
		• Root user privileges
			• Root user = Account Owner (created when the account is created) who has complete access to all AWS services and resources
			• Lock away your AWS account root user access keys and do not use the root account for everyday tasks, even administrative tasks
			• Actions that can be performed only by the root user:
				• Change account settings(account name, email address, root user password, root user access keys)
				• Close your AWS account
				• Change or cancel your AWS Support plan
				• Register as a seller in the Reserved Instance Marketplace(seller example, in case you own reserved instance that is not needed anymore)
				• View certain tax invoices
				• Restore IAM user permissions
				• Configure an Amazon S3 bucket to enable MFA
				• Edit or delete an Amazon S3 bucket policy that includes an invalid VPC ID or VPC endpoint ID
				• Sign up for GovCloud


		• To Access AWS
			1. AWS management Console (protected by password + MFA(via Virtual/Physical MFA device)) - Web Interface
			2. AWS CLI (Protected by Access Keys) - access keys are single time given credentials(id and secret key) to access AWS services from terminal of our PC
			3. AWS SDK (for application code(coding language specific): protected by access keys) - access and manage AWS services programmatically embedded within application

			Note - Access keys are generated through AWS Management Console
					Access Key Id (like username)
					Access Key (like secret password)


		AWS IAM(IAM Identity and Access Management) - Global service (For trusted users and belong to your company)
				- create users(of your org) and assign them to user access groups(according to department) inside AWS
				- JSON document called policies are used to define the permissions for users/group/role
                - Free to use

				IAM Policy structure - 
					- consists of -
						"Version": policy language version, generally we use "2012-10-17"
						"Id": an identifier for the policy(optional)
						"Statement" : one or more individual statements (required)
							Statement consist of - 
								"Sid" : identifier for statement(optional)
								"Effect" : "Allow" or "Deny", defines the statement whether it allows of denies access to certain APIs
								"Principal" : account/user/role to which this policy applied to
								"Action" : list of actions this policy allows or denies
								"Resource" : list of resources to which the action applied to 
								"Condition" : condition for when this policy is in effect(optional)

					- example policy;
						{
							"Version" : "2012-10-17",
							"Id" : "S3-Account-Permissions",
							"Statement" : [
								{
									"Sid" : "1",
									"Effect" : "Allow",
									"Principal" : {
										"AWS" : ["arn:aws:iam::123456789012:root"]
									},
									"Action" : [
										"iam:List*",
										"s3:ListBucket",	 // bucket level permission
										"s3:GetObject",		|
										"s3:PutObject",		|// object level permissions
										"ec2:StopInstances",
										"kms:DescribeKey"
									],
									"Resource" : ["arn:aws:s3::mybucket", "arn:aws:s3::mybucket/*", "arn:aws:ec2:ap-south-1:123456789012:instance/*"],
									"Condition" : {
										"NotIpAddress" : {
											"aws:SourceIp" : ["192.0.2.0/24", "203.0.113.0/24"]
										},
										"stringEquals" : {
											"aws:RequestedRegion" : ["ap-south-1", "eu-west-1"],		// only to allow API calls to a specified AWS region
											"ec2:ResourceTag/Project":"MyProject",
											"aws:PrincipalTag/Department" : "Data",
											"aws:PrincipalOrgID" : "o-yyyyyyyyyy",
											"kms:CallerAccount" : "123456789012",
											"kms:ViaService" : ["ec2.ap-south-1.amazonaws.com", "sqs.ap-south-1.amazonaws.com"]
										},
										"BoolIfExists":{
											"aws:MultiFactorAuthPresent" : true
										}
									}
								}
							]
						}

				IAM Roles (Proxy - assumes assigned permission)
					- Assigning specific permissions for the AWS services/accounts/external Web Identity for accessing AWS resources temporarily by forfaiting own permissions
					- Roles provide temporary security credentials(not userid/pass) to whomever has the ability to assume that role
				
				Resource Based Policy
					- Attached on supported resources(S3 buckets, SNS topics, SQS queues, etc.) for becoming accessible from defined service/account

				IAM Security Tools(Audit permissions of accounts)
					IAM Credentials Report (account-level)
						- a report that lists all your account's users and the status of their various credentials

					IAM Access Advisor (user-level)
						- Access advisor shows the service permissions granted to a user and when those services were last accessed by users.

					IAM Access Analyzer
						- Find out which resources are shared externally(Access outside zone of trusts) and provides findings
							• S3 Buckets
							• IAM Roles
							• KMS Keys
							• Lambda Functions and Layers
							• SQS queues
							• Secrets Manager Secrets
						- Define Zone of Trust = AWS Account or AWS Organization

				IAM User Group
					- IAM User Groups can contain only IAM Users


		AWS IAM Identity Center (formarly AWS Single Sign-On)
			- Managing one login centrally across multiple;
					• AWS accounts in AWS Organizations
					• Business cloud applications(e.g., Salesforce, Box, Microsoft 365, etc.)
					• SAML2.0 enabled applications
					• EC2 Windows Instances
			- built-in identity store in IAM Identity Center or integrated to 3rd party identity providers(Active Directory(AD), OneLogin, Okta) for user pool
			- allow restricting user/group access according to the defiend "Permission Set"(collection of IAM policies) to assume role for accessing allowed resources




	Advanced Identity
		AWS Organizations - Global Service (for multi-account management)
			- Used to manage multiple child/member accounts(can be part of only one OU(organizational unit)) under single Master/Management account
			- Service Control Policies(SCP) 
				• IAM policies applied on OU or accounts
				• To centrally manage all IAM users, groups, and roles, including the AWS account root user
				• SCP does not apply to the Master/Management Account and service-linked roles(enables AWS services to integrate with AWS Organizations)
				• Defaultly everything is restricted, have to explicitly Allow account privileges
				• Use case; restrict access to certain services, enforce PCI compliance by explicitly disabling services
			- Cost Benefits
				• consolidated billing(one bill) across all accounts(no need to add payment method for all accounts)
				• aggregated usage results pricing benefits(volume discount for EC2, S3, etc.)
				• effective sharingly usage of reserved EC2 instances for optimal savings
				• Use tagging standards for billing & monitoring purposes
			- API is available to automate AWS account creation
			- management account can turn off Reserved Instances discount sharing for any account in the AWS Organization, including itself
			- Multi Account strategies
				• Create account(Organizational Units);
					- per department
					- per cost center
					- per environment(dev/test/prod)
					- based on regulatory restrictions(using SCP)
					- for better resource isolation(eg. VPC)
					- to have separate per-account service limits
					- isolated account for logging
				• Single point of config to Enable CloudTrail on all accounts to send logs to central S3 account as well as send CloudWatch Logs to central logging account   


		AWS Control Tower
			- gives ability to easily set-up and govern a secure and compliant multi-account AWS environment(using AWS Organization) based on best practices
			- Runs on top of AWS Organizations; automatically sets up AWS Organizations to organize accounts and implement SCPs(Service Control Policies)
			- Benefits;
				• Automate the set up of your environment in a few clicks
				• Automate ongoing policy management using Control Tower Guardrail(governance rules on OU to enforce policiesusing SCP or violation detection using AWS Config)
				• Detect policy violations and remediate them
				• Monitor compliance through an interactive dashboard


        AWS Resource Access Manager(RAM)
            - Share AWS resources that you own with other AWS accounts, whether they're in your organization or not
            - Helps to avoid resource duplication!
            - Supported resources include Aurora DB, VPC Subnets, Transit Gateway, Route 53, EC2 Dedicated Hosts, License Manager Configurations, etc.


        AWS Service Catalog
            - Users that are new to AWS have too many options, and may create stacks that are not compliant/in-line with the rest of the organization
            - Provides quick self-service portal(instructions) to launch a set of authorized products pre-defined by admins; Includes: virtual machines, databases, storage options, etc.
            - Admins pre-configure the Cloudformation templates and gives specific permissions to access and use those templates portfolio


        AWS STS(Security Token Service)
            - Create temporary, limited privileges credentials(access key, session key) to access your AWS resources
            - Short-term credentials: configurable expiration period
            - Use cases
                • IAM Roles for cross/same account access
                        IAM Role(same/cross account)                    ==(assume role)==>                      
                                    User                         <==(temporary security credentials)==                   AWS STS 
                • Identity federation: manage user identities in external systems, and provide them with STS tokens to access AWS resources
                • IAM Roles for Amazon EC2: provides temporary credentials for EC2 instances to access AWS resources


		AWS Cognito
			• Cognito User Pools:
				- Managed, serverless database of users(potentially millions) for your Web/Mobile app with redirection sign-in of Facebook, Google, and Twitter
				- Integrate with API Gateway & Application Load Balancer
			• Cognito Identity Pools (Federated Identity):
				- Instead of creating them an IAM user, provides temporary AWS credentials to registered users of our application to access some resources of AWS directly
				- Integrate with Cognito User Pools as an identity provider
				- Use Case : Create mobile user accounts and provide IAM permissions, so they can be able to access their own personal space in the S3 bucket


		AWS Directory Services
			- Microsoft Active Directory (AD) : doesn't belong to AWS
				• On Windows Server that has AD domain services, AD is a central system that manages users and their access to network resources
				• Handles logins and permissions, making network administration easier
				• AD is way for you to manage user accounts, computers, printers, file shares, security groups and so on, usually within on-premises system

			3 types of AD available in AWS
				• AWS Managed Microsoft AD	
					- Create your own AD in AWS to manage users locally with MFA support
					- Establish “trust” connections with on-premise AD & AWS Managed AD
				• AD Connector
					- Directory Gateway(proxy) to redirect directory requests to your existing on-premise AD with MFA support
					- Users are managed only on-premise AD
				• Simple AD
					- AD-compatible stand-alone managed directory on AWS
					- Cannot be joined with on-premise AD


		Amazon WorkSpaces
			- Managed Desktop as a Service(DaaS-fully managed VDI and desktop) solution to easily provision Windows or Linux desktops
			- Great to eliminate management of on-premise VDI(Virtual Desktop Infrastructure)
			- Fast(Regional-should be provisioned close to users Region) and quickly scalable to thousands of users
			- Secured data : integrates with KMS
			- Pay-as-you-go on-demand service with monthly or hourly rates


		Amazon AppStream 2.0
			- Desktop Application Streaming Service - Stream a desktop application to web browsers (no need to connect to a VDI)
			- Deliver to any computer(that has a web browser), without acquiring, provisioning infrastructure as application is delivered from within a web browser
			- Allow to configure an instance type per application type (CPU, RAM, GPU)




	Billing
        Pricing Models in AWS
            - AWS has 4 pricing models;
                • Pay as you go : pay for what you use, remain agile, responsive, meet scale demands
                • Save when you reserve : minimize risks, predictably manage budgets, comply with long-terms requirements
                    - Reservations are available for 
                        EC2 Reserved Instances
                        DynamoDB Reserved Capacity
                        ElastiCache Reserved Nodes
                        RDS Reserved Instance
                        Redshift Reserved Nodes
                • Pay less by using more : volume-based discounts
                • Pay less as AWS infrastructure and usage grows

            - Free services & free tier in AWS
                - IAM
                - VPC
                - Consolidated Billing
                - Elastic Beanstalk				|
                - CloudFormation				|-> You do pay for the resources created
                - Auto Scaling Groups			|
                - Free Tier: https://aws.amazon.com/free/
                    • EC2 t2.micro instance for a year
                    • S3, EBS, ELB, AWS Data transfer upto certain amount

			- Networking Costs in AWS per GB
				• Traffic Cost; 
					- Free for inbound traffic
					- Free for traffic between 2 EC2 in same AZ with private IP
					- $0.01/GB, for traffic between 2 EC2 in different AZ if using private IP
					- $0.02/GB, for traffic between 2 EC2 in different AZ if using public/elastic IP as traffic have to go via Internet
					- $0.02/GB, for traffic between 2 EC2 in different Regions
				• Recommended to use Private IP instead of Public IP for good savings and better network performance
				• Use same AZ for maximum savings(trade-of with high availability)
				• Charges for IPv4 address creation;
					- For all AWS services(except EC2) starting from 1st Feb 2024, all public IPv4 created(to access your services like s3 hosted static website) in a account
					- $0.005 per hour of public IPv4 (~$3.6 per month)
					- For new accounts in AWS, you have a free tier for the EC2 service: 750 hours of AWS charges for PM IPv4 per month for 12 months

					Note - to monitor pulic IP address in use : "Amazon VPC IP Address Manager" -> "Public IP insights"


		Savings Plans (Alternative to Reserved Instances)
			- Easiest way to setup long-term commitments on AWS
			- Commit a certain amount per hour for 1 or 3 years
			- EC2 Savings Plan
				• Up to 72% discount compared to On-Demand
				• Commit to $10/hour for three years on C5 instances in a region regardless of AZ, size(m5.xl to m5.4xl), OS(Linux/Windows) or tenancy(shared/dedicated host)
				• All upfront, partial upfront, no upfront
			- Compute Savings Plan
				• Up to 66% discount compared to On-Demand
				• Regardless of Family, Region, size, OS, tenancy, compute options
				• Compute Options: EC2, Fargate, Lambda
			- Machine Learning Savings Plan: SageMaker, etc.
			- Setup from the AWS Cost Explorer(Billing and Cost Management) console
			- Estimate pricing at https://aws.amazon.com/savingsplans/pricing/


		AWS Compute Optimizer
			- Reduce costs and improve performance by recommending optimal AWS resources for your workloads using ML
			- Helps you choose optimal configurations and right size your workloads(over/under provisioned)
			- Uses Machine Learning to analyze your resources’ configurations and their utilization CloudWatch metrics
			- Supported resources
				• EC2 instances
				• EC2 Auto Scaling Groups
				• EBS volumes
				• Lambda functions
			- Lower your costs by up to 25%
			- Recommendations can be exported to S3


		AWS Billing and Cost Management
			- Estimating costs in the cloud:
				• AWS Pricing Calculator https://calculator.aws/ - Estimate the cost(for year) for your solution architecture
			- Tracking costs in the cloud:
				• AWS Billing Dashboard	- shows all the costs actually for the month
				• Cost Allocation Tags - AWS generated(Automatically as resource is created) or User-defined(Name, Environment, Team) tagged resources to track your AWS costs
				• Cost and Usage Reports 
                    - comprehensive report including additional metadata about AWS services, pricing, and reservations
                    - lists AWS usage for each service category used by an account and its IAM users in hourly or daily line items, as well as any tags that you have activated for cost allocation purposes
				• Data Export - Provides custom reports with analyzing data at a high level(total costs and usage across all accounts) on monthly, daily, hourly or resource level info
				• Cost Explorer - View current usage(detailed) and forecast usage
                    - Visualize, understand, and manage your AWS costs and usage over time
                    - Provides data at a high level(total costs and usage across all accounts) on monthly, daily, hourly or resource level info
                    - Forecast future usage up to 12 months based on previous usage to choose an optimal Savings Plan(to lower prices on your bill)
			- Monitoring against costs plans:
				• Billing Alarms
				• Budgets


        AWS Resource Group
            - Grouping/tagging for organizing resources to make easy cost management on a detailed level
            - if we create resources through CloudFormation, they will all be tagged the same way


        Billing Alarms in CloudWatch(only available in us-east-1)
            - Billing data metric is stored for overall worldwide(regions) AWS costs
            - It’s for actual cost, not for projected costs
            - only send alerts(email notification) when your costs and usage are exceeding your budget, while AWS Budgets also alerts when it is forecasted to exceed your budget


        AWS Budgets
            - Create budget and send alarms when costs exceeds the budget or forcast
            - 4 types of budgets: 
                • Usage
                • Cost
                • Reservation
                • Savings Plans
            - For Reserved Instances (RI)
                • Track utilization
                • Supports EC2, ElastiCache, RDS, Redshift
            - Up to 5 SNS notifications per budget
            - Can filter by: Service, Linked Account, Tag, Purchase Option, Instance Type, Region, Availability Zone, API Operation, etc.
            - Same options as AWS Cost Explorer!
            - Pricing; 2 budgets are free, then $0.02/day/budget


        AWS Cost Anomaly Detection
            - Continuously monitor your cost and usage(AWS services, member accounts, cost allocation tags, or cost categories) using ML to detect unusual spends and send alerts
            - Learns from unique, historic spend patterns to detect one-time cost spike and/or continuous cost increases (you don’t need to define thresholds)
            - Sends you the anomaly detection report with root-cause analysis
            - Get notified with individual alerts or daily/weekly summary(using SNS)


        AWS Service Quotas
            - Create CloudWatch Alarms on the Service Quotas console when usage is close to a service quota value threshold
            - We can request a quota increase from AWS Service Quotas or shutdown resources before limit is reached




	Support
        AWS Trusted Advisor
            - online tool that provides you real-time guidance to help you provision your resources. e.g. do you have EBS/RDS Public Snapshots? Or are you using the root account for your accounts?
            - high level AWS account assessment to analyze your AWS accounts and provides recommendation following AWS best practices on:
                • Operational Excellence
                • Security(some of the checks are free)
                • Fault tolerance
                • Performance
                • Cost optimization
                • Service limits(0 of 5 RDS reads usage is more than 80% of the service limit)
            - Only for Business & Enterprise Support plan
                • Full Set of Checks
                • Programmatic Access to Trusted Advisor using AWS Support API


        Professional Services of AWS
            - global team of experts working alongside users team and a choosen member of APN

        AWS Partner Network(APN)
            - The AWS Partner Network is the global partner program for technology and consulting businesses that leverage AWS to build solutions and services for customers

            APN Consulting Partner
                - professional services firms; provides all types and sizes design, architect, build, migrate, and manage their workloads and applications on AWS, accelerating their migration to AWS cloud

            APN Technology Partner 
                - provides hardware, connectivity services, or software solutions that are either hosted on or integrated with, the AWS Cloud

                APN Training Partner  
                    - find who can help you to learn AWS
                
                AWS Competency program
                    - aws Competencies given to APN Partners who have demonstrated technical proficiency and proven customer success in specialized solution area
            
            AWS Navigate program
                - help Partner to become better partner

            AWS IQ
                - Quickly find Professional help for users AWS project, out of third-party experts that are AWS Certified and available for on-demand project work to engage and get paid
                - provides you with video conferencing, contract management features, secure collaboration and integrated billing

            AWS managed services(AMS)
                - Team of AWS experts to provide you infrastructure and application support 24/7 on AWS
                - Handles routine management tasks such as change requests, monitoring, patch management, security and backup services following best practices


        AWS Support Plans Pricing
            - AWS Basic Support Plan(Free)
                • Customer Service & Communities : 24x7 access to customer service, documentation, whitepapers, and support forums
                • AWS Trusted Advisor : Access to the 7 core Trusted Advisor checks and guidance to provision your resources following best practices to increase performance and security
                • AWS Personal Health Dashboard : A personalized view of the health of AWS services, and alerts when your resources are impacted
            - AWS Developer Support Plan
                • All Basic Support Plan +
                • Business hours email support to Cloud Support Associates
                • Unlimited cases/unlimited contacts
                • Based on the case severity, you get response times;
                    - General guidance: respond in less than 24 business hours
                    - System impaired: respond in less than 12 business hours
            - AWS Business Support Plan (24/7)
                • Intended to be used if you have production workloads
                • Trusted Advisor with Full set of checks + API access
                • 24x7 phone, email, and chat access to Cloud Support Engineers
                • Unlimited cases/unlimited contacts
                • Access to Infrastructure Event Management for additional fee.
                • Based on the case severity, you get response times;
                    - General guidance : respond in less than 24 business hours
                    - System impaired : respond in less than 12 business hours
                    - Production system impaired : respond in less than 4 hours
                    - Production system down : respond in less than 1 hour
            - AWS Enterprise On-Ramp Support Plan (24/7)
                • Intended to be used if you have production or business critical workloads
                • All of Business Support Plan +
                • Access to a pool of Technical Account Managers(TAM)
                • Concierge Support Team(for AWS billing and account best practices helps)
                • Oprational reviews : Infrastructure Event Management, Well-Architected & Operations Reviews
                • Based on the case severity, you get response times;
                    - same as above...
                    - Business-critical system down: respond in less than 30 minutes
            - AWS Enterprise Support Plan (24/7)
                • Intended to be used if you have mission critical workloads
                • All of Business Support Plan +
                • Access to a designated Technical Account Manager(TAM)
                • Concierge Support Team(for AWS billing and account best practices helps)
                • Infrastructure Event Management, Well-Architected & Operations Reviews
                • Access to AWS Incident Detection and Response(for an additional fee)
                • Based on the case severity, you get response times;
                    - same as above...
                    - Business-critical system down: respond in less than 15 minutes




	Architecting & Ecosystem
		• Well Architected Framework General Guiding Principles
			- Stop guessing your capacity needs - use auto scaling and scale the based on what the actual demand on your system is going to be
			- Test systems at production scale
			- Automate to make architectural experimentation easier 
				• CloudFormation;  infrastructure as code can easily create an architecture on different accounts and different regions
				• BeanStalk;  platform as a service
			- Allow for evolutionary architectures - design based on changing requirements. for example, make serverless designs(Developers don’t have to manage/provision servers instead it's managed/provisioned by AWS)
			- Drive architectures using data - choose architecture and services based on actual usage, patterns, queries and what you actually need based on this data
			- Improve through game days - Simulate applications for flash sale days for sudden stike of traffic, failover simulation


		AWS Cloud Best Practices : Design Principles
			Scalability: ability to accommodate a larger load
				1. Vertical Scalability
					- flexible capacity/size of instance, Of'course with upto H/W limits
					- scale up/down
				2. Horizontal Scalability(elasticity)
					- flexible number of instances/systems, parallel execution
					- scale out/in using ASG and ELB
            Availability: fault tolerance with appropriate back-up failovers using ASG and ELB across multi AZ
			Agility: gives ability make users work faster as creation and deletion happens qickly
			Disposable Resources: servers should be easily disposable & easily configurable
			Automation: use Serverless, Infrastructure as a Service, Auto Scaling, etc.
			Loose Coupling: Break it down into smaller, loosely coupled(independant) components
			Services, not Servers: Refrain using EC2, use managed services(serverless), databases, etc.


		Well-Architected Framework 6 Pillars
			1. Operational Excellence
				- Ability to run and monitor systems to deliver business value and to continually improve supporting processes and procedures
				- Design Principles;
					• Perform operations as code - Infrastructure as code, i.e. make use of Cloudformation
					• Make frequent, small, reversible changes - So that in case of any failure, you can reverse it
					• Refine operations procedures frequently and ensure that team members are familiar with it
					• Anticipate failure
					• Learn from all operational failures
					• Use managed(serverless) services - to reduce operational burden
					• Implement observability for actionable insights - performance, reliability, cost, etc.
			2. Security
			3. Reliability  : Testing recovery procedures, stopping guessing capacity, and managing changes in automation
			4. Performance Efficiency   : democratize advanced technologies, go global in minutes, use serverless architecture, experiment more often, mechanical sympathy
			5. Cost Optimization
			6. Sustainability

			Note; These 6 are not something to balance or trade-offs, they’re a reccomandations


		AWS Well-Architected Tool
			- Free tool to review your architectures and adopt architectural best practices by Simulating workload and answering questions on the Well-Architected Framework 6 pillars


		AWS Customer Carbon Footprint Tool
			- Track, measure, review, and forecast the Carbon emissions generated from your AWS usage
			- Helps you meet your own sustainability goals


		AWS Cloud Adoption Framework(AWS CAF)
			- Not a service but a Ebook/whitepaper which helps to build and then execute a comprehensive plan for your digital transformation through innovative use of AWS
			- Created by AWS Professionals by taking advantage of AWS Best Practices and lessons learned from 1000s of customers
			- AWS CAF allows to identifies specific organizational capabilities that underpin successful cloud transformations
			- AWS CAF groups its capabilities in six perspectives:
				Business 
				People
				Governance 
				Platform
				Security
				Operations


		Free AWS Ecosystem
			AWS Blogs: get new feature release, as well as in-depth article around how to do a specific use case
			AWS Partner Solutions (formerly Quick Starts): automated reference deployments built by AWS solutions architects and AWS Partners to start using your environment within minutes
			AWS re:POST(community - AWS managed QnA service): engaging with other developer/architect in community, thats why not for questions that are time sensitive and involves personal information
			AWS Whitepapers & Guides: to learn in depth around a specific area of AWS
			AWS Solutions Library(formerly Quick Starts): use case based technical content pool with architectural digrams based on best practices, authored by AWS and the AWS community to expand your knowledge of the cloud


		AWS Marketplace
			- we can sell your own solutions on the AWS Marketplace
			- Digital catalog with thousands of software listings from independent 3rd-party software vendors
				• Custom AMI (custom OS, firewalls, technical solutions)
				• CloudFormation templates
				• Software as a Service
				• Containers
			- buying/selling cost will be added to your AWS bill


		AWS Training
			- Digital(online) and classroom Training(in-person or virtual)
			- Also provides private training(for organization)
			- Dedicated training and certification for US Government
			- Enterprise training and certification
			AWS Academy : helps universities teach AWS




	Cloud Migration Essentials
		Cloud Migration Strategies : The 7Rs
			Retire : Turn off things you don’t need(maybe as a result of Re-architecting) and only focus your attention on resources that must be maintained
				- Helps with reducing the surface areas for attacks(more security) 
				- Save cost, maybe up to 10% to 20%
			
			Retain : filter/shorlist the services for cloud migration
				- because of Security, data compliance, performance, unresolved dependencies
				- No business value to migrate, mainframe or mid-range and non-x86 Unix apps
			
			Relocate : Move apps from on-premises to its Cloud version or move EC2 instances to a different VPC, AWS account or AWS Region
				- Example: transfer servers from VMware Software-defined Data Center(SSDC) to VMware Cloud on AWS
			
			Rehost “lift and shift” : Simple migrations without cloud optimizations, applications is migrated as it is
				- By re-hosting(applications, databases, data) or migrating machines(physical, virtual, another Cloud) to AWS Cloud
				- Could save as much as 30% on cost
				- Example: Migrate using AWS Application Migration Service

			Replatform “lift and reshape” : migrating without changing the core architecture, but leverage some Cloud optimizations
				- Save time and money by moving to a fully managed service or Serverless
				- Example: migrate your database to RDS or migrate your application to Elastic Beanstalk
			
			Repurchase “drop and shop” : Moving to a different product(SaaS platform) while moving to the Cloud
				- Expensive in the short term, but quick to deploy
				- Example: CRM to Salesforce.com, HR to Workday, CMS to Drupal
			
			Refactor/Re-architect : Reimagining how the application is architected using Cloud Native features
				- Driven by the need of the business to add features and improve scalability, performance, security, and agility
				- Move from a monolithic application to micro-services
				- Example: move an application to Serverless architectures, use AWS S3


		AWS Application Discovery Service
			- Plan migration projects by gathering information like Server utilization data and dependency mapping about on-premises data centers
			AWS Agentless Discovery Connector(for Agentless Discovery)
				- gives information about VM inventory, configuration, and performance history such as CPU, memory, and disk usage
			AWS Application Discovery Agent(for Agent-based Discovery)
				- gives lower level of information like System configuration, system performance, running processes, and details of the network connections between systems
			AWS Migration Hub : for AWS DMS(Database Migration Service) & AWS Application Migration Service(MGN)
				- central location to collect server and applications inventory data from AWS Application Discovery Service, for the assessment, planning and tracking of migrations to AWS
				AWS Migration Hub Orchestrator : provides pre-built templates to save time and efforts migrating enterprise apps(eg. SAP, MS SQL server)
		

		AWS Application Migration Service(MGN) 
			- Lift-and-shift(rehost) solution, in which we converts physical, virtual, and other cloud-based servers to run natively on AWS
			- Minimal downtime, reduced costs
			- Supports wide range of platforms, Operating Systems, and databases


		AWS Migration Evaluator
			- Helps you build a data-driven business case for migration to AWS
			- Provides a clear baseline of what your organization is running today by conducting broad-based discovery using Agentless Collector
			- Take a snapshot of on-premises foot-print, server dependepncies, etc. then analyze current state, define target state, then develop migration plan


		AWS DataSync
			- Move large amount of data from on-premises/other cloud(using Datasync Agent), AWS(without agent) to AWS S3(any storage classes; including Glacier), EFS, FSx
			- Replication tasks are incremental and is not continuous but is only scheduled hourly, daily, weekly
			- File permissions and metadata are preserved/copied while moving like NFS POSIX, SMB file system
			- Agent has ability to use 10 GB/s. But to avoid network usage, either set a bandwidth limit or use AWS Snowcone which comes pre-installed Datasync agent




	Global Cloud Infrastructure
		• Gives ability to create global application(deployed in multiple geographies - Regions and/or Edge Locations) for 
		• For; Decreased Latency, Disaster Recovery, Attack protection from 
		
		• Global Application Architectures		
			1. Single Region, Single AZ		✕ High Availability;  ✕ Global Latency;   Low Difficulty
			2. Single Region, Multi AZ		✓ High Availability;  ✕ Global Latency;   Modrate Difficulty 
			3. Multi Region, Active-Passive	✓ High Availability;  ✓ Global Reads’ Latency;  ✕ Global Writes’ Latency;   Modrate Difficulty 
			4. Multi Region, Active-Active	✓ High Availability;  ✓ Global Reads’ Latency;  ✓ Global Writes’ Latency;   High Difficulty
		
		• AWS Global infrastructure - https://infrastructure.aws/
			AWS Regions [ Asia Pacific(Mumbai) : ap-south-1, Asia Pacific(Sydney) : ap-southeast-2, US East(Ohio) : us-east-2 ]
					- Geographic areas containing multiple, isolated data centers(Physical facilities housing servers, networking equipment and other infrastructure) 
					- most AWS services are region scoped(service behaves as new if region is changed)
					For launching new application, how should you choose the region?
						- compliance : with gov and legal requirements
						- latency : according to users' locations to give them min latency
						- service availability
						- pricing : vary from region to region

			AWS Availability zones(AZ) [ ap-south-1a, ap-south-1b ap-south-1c ]
					- Each region has at least 3 isolated availability zones(2 or more data centers) connected with high bandwidth ultra-low latency network
					- linked altogether forming a region

			AWS Local Zones [ Kolkata : ap-south-1-ccu-1a, Delhi : ap-south-1-del-1a ]
					- Bring AWS resources (compute(EC2, ECS), database(RDS, ElastiCache), storage(EBS), etc.) closer to your end users for latency-sensitive applications
					- Optional, i.e. must be enabled manually to extend your VPC to more locations

			AWS WaveLength [ ap-south-1-wl1-mum-wlz-1, ap-south-1-wl1-ccu-wlz-1 ]
					- Brings AWS services(EC2, EBS, VPC, etc.) embedded within the telecommunications providers datacenters at the edge of the 5G networks
					- Optional, i.e. must be enabled manually, without any additional charges or service agreements
					- Ultra-low latency applications through 5G networks as Traffic doesn’t leave the Communication Service Provider’s (CSP) network

			AWS Edge Locations/Points of Presence - AWS has 400+ Points of presence
					- Network infrastructure points strategically located around the world
					- Improve latency and performance for applications and services
					- generally used for Cloudfront Distributions(Global Content Delivery Network)


		AWS Route53 : Global DNS + AWS Domain Registrar(like GoDaddy)
			- Managed DNS(Domain Name System) inform users about the closest deployed node with least latency and disaster recovery strategies
			- Allows global(from 15 regions;> 18% healthy reports considered as healthy) health checks for AWS public(HTTP/HTTPS/TCP) or private(CloudWatch alarm) resources
				• Health Checks can be setup to pass/fail based on the text in the first 5120 bytes of the response
				• Combine the results of upto 256 Child Health Checks(for EC2 instances, etc.) into a single Parent Health Check with specified min child healthiness considers parent as healthy
			- Only AWS service which providing 100% availability SLA
			- port 53 is the traditional DNS port, therefore name Route 53
			- allows using domain from a 3rd party registrar to use Route 53 as the DNS service provider by using Route 53 Name Servers on NS Records on 3rd party website
			- In AWS, the most common records are:
				• A (IPv4)  										|	www.google.com 	=>  12.34.56.78
				• AAAA (IPv6) 										| 	www.google.com 	=>  2001:0db8:85a3:0000:0000:8a2e:0370:7334
				• CNAME: hostname to target hostname(only A/AAAA)	| 	search.google.com =>  www.google.com
					- Can’t create a CNAME record for the "top node of a DNS namespace"(example.com) as this needs A & NS records but CNAME can't coexist with other DNS records, but you can CNAME create for subdomain(www.example.com)
				• Alias (A/AAAA record with Alias enabled for AWS) 	| 	example.com 	=>  AWS resource(ex: ELB, CloudFront distribution, S3 websites, API Gateway api, VPC interface endpoints, Elastic Beanstalk env., Global accelerator, Route 53 Record(Same Hosted Zone), etc.)
					- Alias records are pointers to other AWS resources not actual DNS records
					- Unlike CNAME, Alias can be used for "top node of a DNS namespace"(example.com)
					- Alias is free of charge; auto recognizes changes in the resource’s IP addresses with additional health check ability of target resource
					- TTL value cannot be configured directly for Alias Record, automatically managed by Route 53
					- Couldn't set an Alias record for an EC2 DNS name
				• NS(Name Servers for the Hosted Zone)				|	DNS names or IP addresses of the servers to respond the DNS queries for your hosted zone
				• with additional advanced record types; CAA, DS, MX(for email delivery), NAPTR, PTR, SOA, TXT(for SPF, DKIM, or domain verification), SPF, SRV, etc.
			- Route53 Hosted Zone : container of records that define how to route traffic for a domain and its subdomains
				1. Public : Publically accessible for public domain name resolution(anyone from internet query domain name to get IP of actual server)
				2. Private : route traffic within one or more VPCs to the private domain names
			- Pricing;
				• Charges $0.50 per month per hosted zone registration
				• Route 53 domain regitration costs $12-$13 per year
				• price per request reaching Route 53(except for Alias record)
			- Each DNS record(rules to route traffic) contains:
				1. Domain/subdomain Name. e.g., example.com
				2. Record Type. e.g., A or AAAA
				3. Value. e.g., 12.34.56.78
				4. Routing Policy : how Route 53 responds to queries
				5. TTL(Time To Live) : amount of time the record cached at local DNS Resolvers of client; mandatory for all DNS, exept Alia Records
			- Routing(only for DNS queries) Policies:
				• Simple routing policy : Web browser(foo.example.com) ⇄ (A:11.22.33.44)Route 53
					- only type with no health checks
					- random one is chosen if multiple values(addresses) are returned, thats why only one AWS resource should be specified when Alias Enabled
				• Weighted routing policys :	(DNS queries) =>  { EC2_1(70%) | EC2_2(20%) | EC2_3(10%) }
				• Geolocation : based on user location specified by continent, country, state; routes to created “Default” record incase there’s no match on location
				• Latency based routing policy
				• Failover routing policy : (DNS queries)=>  { if  healthy_primary:   EC2(primary)  else  EC2(secondary/failover) }; only one primary and one secondary/failover
				• Geoproximity (using Route 53 Traffic Flow) : route traffic based on the geographic location of users and resources(AWS region or Latitude-Longitude) with defined bias/weight rules
				• IP-based Routing : Routing is based on clients’ IP(list of CIDRs) addresses from a particular ISP to a specific endpoint
				• Multi-Value Answer : to route traffic to multiple(only healthy; max 8) resources; used for client side load balancing(different than ELB)


		AWS Cloudfront : Global Content Delivery Network(CDN) Service
			- Replicates the part of your application to AWS Edge Locations(216 Point of Presence globally) for lowest latency access
			- Cache common and frequent requests; improves user experience and decreased latency
			- CloudFront - Origins(locations where your original content is stored)
				• S3 bucket
					- For distributing files(static content) and caching them at the edge; also be used as to upload files to S3 using AWS network from CloudFront to S3
					- Enhanced security with CloudFront Origin Access Control(OAC) replacing old Origin Access Identity(OAI) for traffic to/from S3-CloudFront Origin
					- Cloudfront vs S3 Cross Region Replication	
						• Cloudfront is a Global-CDN with Global TTL-based caching  ||  S3 Replication is a storage service for Regional data availability and disaster recovery	
						• For the static content that must be available everywhere  ||  For the dynamic content that needs to be available at low-latency in few regions
                • VPC Origin
                    - For delivering content from application hosted in VPC private subnet without exposing them on the Internet
                    - ALB/NLB/EC2 Instance; Cloudfront can privately connects to these
                • Custom Origin (HTTP)
					- S3 website(must first enable the bucket as a static S3 website)
					- Any HTTP backend you want
					- Edge Function((CloudFront Functions & Lambda@Edge))
			- Security;
				• DDoS protection(because application lives worldwide)
				• integration with Shield and AWS Web Application Firewall
				• Geo Restriction : allow/block users to access content based on location/countries, location is determined using a 3rd party Geo-IP database
				• Cache Invalidation : To force cache(filterd{/images/*} or all{*}) refreshing regardless of TTL expiry, used to 
			- Pricing;
				• Billed for data transfer-out(with volume discount - more the data, less the price) but not for transfer-in
				• Cost for data out per edge location is different across different geographic regions
				• Number of HTTP/HTTPS requests
				• Aggregated for each edge location, then applied to your bill
				• Based on Price class;
					1. Price Class All: all regions, best performance
					2. Price Class 200: most regions, excluding most expensive regions
					3. Price Class 100: only least expensive regions
			- Edge Function(CloudFront Functions & Lambda @ Edge) : code attached to CloudFront distributions runs close to users for minimum latency
				1. CloudFront Functions : Native CloudFront feature only for client req/res; lightweight, high-scale(millions req/s), latency-sensitive JavaScript functions
				2. Lambda@Edge : for client and origin(server) req/res from CloudFront; auto scaled(1000s of req/s) NodeJS/python functions; CloudFront replicates function to its locations
				• Use Cases; customize the CDN content, Dynamic Web Application at the Edge, Search Engine Optimization (SEO)


		AWS S3 Transfer Acceleration
			- Accelerate global uploads & downloads by transferring file to an AWS edge location which will forward the data to the S3 bucket in the target region 
			- File in USA   ==(public WWW)==>   Edge Location in USA   ==(private AWS)==>   S3 Bucket in Asia


		AWS Global Accelerator
			- Unicast IP(one server holds one IP address) vs Anycast IP(all servers hold the same IP address and the client is routed to the nearest one)	
			- Improve global application availability and performance by Leveraging the AWS private global network through Edge Locations to optimize the route to your applications
			- 2 Global Anycast IPs are created for your application for sending users traffic directly to closest Edge location to further get that traffic to application via pvt AWS network
			- works with; Elastic IP, public or private EC2 instances, ALB, NLB allowing spplication health checks and fast regional failover
			- Security;
				• only 2 external IP(static) need to be whitelisted
				• Provides DDoS protection leveraging AWS Shield
			- CloudFront vs Global Accelerator
				• Caches content (images, videos) at global edge locations for faster delivery  ||  proxying packets at the edge to applications in one or more AWS regions, 
				• Reduced upload/download latency  ||  Improves performance(wide range) for TCP/UDP(HTTP) applications requireing static IP and Non-HTTP like UDP(Gaming), VoIP
			- Pricing; expensive service
				• fixed fee $0.025 for every full/partial hour accelerator runs of in account until it deleted
				• data transfer fee : $0.015-0.09 per GB depending upon region


		AWS Outposts
			- AWS infrastructure, services, APIs & tools to build your own(kind of rented from AWS) applications on-premises
			- "Outposts Racks"(server racks) : AWS will setup and manage within your on-premises infrastructure(Data centers) on which you can start leveraging AWS services
			- You are responsible for the Outposts Rack physical security
			- Benefits;
				• Low-latency access
				• Local data processing
				• Easier migration from on-premises to the cloud
				• Fully managed(server management) service
			- services that work on Outposts: EC2, EBS(Elastic Block Store), S3, ECS, EKS(Elastic Kubernetes Service), RDS, EMR(Elastic MapReduce)




	Cloud Integration
		• When we start deploying multiple applications, they will inevitably need to communicate with one another
		• There are two patterns of application communication
			1. Synchronous communications (application to application)
			2. Asynchronous/Event based (application to queue to application) - scales independantly to handle sudden traffic spikes


		AWS SQS: queue model
			- Fully managed oldest(over 10 years) serverless service, used to decouple applications with delayed processing and retries workload failures
			- Low latency (< 10ms on publish and receive) with size limitation of 1-256 KB per message sent
			- Scalable from 1 to 10000 messages/sec without any limit on how many messages available in the queue
			- Default retention of messages: 4 days, maximum retention of 14 days
			- Messages are deleted by consumer itself after they’re read/processed by consumers, otherwise gets duplicate messages(ensuring at-least one delivery) if user doesn’t deletes
			- Working;
															 ↗ CloudWatch Metric  ---->  CloudWatch Alarm ↘
															|											   ASG
				Producers   ---(sending messages)--->   SQS Queue   ---(Polling upto 10 messages)--->   Consumers(deletes Messages after they’re read)
			- Consumers share the work to read(poll) messages & scale horizontally; once message is polled, it becomes invisible to other consumers for defined visibility timeout
			- If message not processed within the visibility timeout, to avoid re-processing consumer could call the ChangeMessageVisibility API to get more time for that one message
			- Long Polling
				• By default, each consumer polls for messages at fixed interval with API call
				• Long Polling allows optionally waits(1-20 sec) for messages to arrive if there are none in the queue
				• Decreases the number of API calls made to SQS while increasing the efficiency and reducing latency of your application
			- Types of SQS Queues;
				1. Standard Queues : for high throughput, not-ordered
				2. FIFO(First-In First-Out) Queue :
					- ordered using Message Group ID(mandatory parameter)
					- exactly-once processing, by optionally removing duplicates using Deduplication ID(given in every message) within 5 min of time range
					- Limited throughput of 300 msg/s without batching, or 3000 msg/s with batching
					- Must be named with suffix '.fifo', eg. "demo-queue.fifo"
			- SQS Access Policies; for cross-account access to SQS queues or allowing other services (SNS, S3 Events, etc.) to write in an SQS queue
			- Encryption
				• In-flight encryption using HTTPS API
				• At-rest(server-side) encryption using SSE-SQS or KMS keys
				• Client-side encryption; if the client wants to perform encryption/decryption itself
			- Dead-Letter Queues(DLQs) used to isolate and analyze messages that have failed to be processed after a certain number of attempts


		AWS SNS(Simple Notification Service - serverless):  topic(publish/subscribe) model i.e. send one message to many receivers
			- The “Publishers” only sends message to one SNS topic but each Subscriber(Up to 12,500,000 per topic) to the topic(Up to 100,000) will get all/filtered(using JSON policy) messages sent
			- No message retention
			- Working
				Publishers   ---(message)--->   SNS Topic   ---(all messages)--->   Subscribers(SQS, Lambda, Kinesis, HTTP/S endpoints, Emails, Mobile Sms and Notifications)
			- Types;
				• Topic Publish(using the SDK)
					- Create a topic
					- Create a subscription (or many)
					- Publish to the topic
				• Direct Publish(for mobile apps SDK)
					- Create a platform application
					- Create a platform endpoint
					- Publish to the platform endpoint
					- Works with Google GCM, Apple APNS, Amazon ADM, etc.
				• SNS FIFO Topic
					Publishers   ---(message-4,3,2,1)--->   SNS FIFO Topic   ---(messages-4,3,2,1)--->   SQS
			- SNS Access Policies; for cross-account access to SNS toipcs or allowing other services (S3 Events, etc.) to write to an SNS topic 
			- Encryption
				• In-flight encryption using HTTPS API
				• At-rest(server-side) encryption using SSE-SQS or KMS keys
				• Client-side encryption; if the client wants to perform encryption/decryption itself


		AWS Kinesis 
			- Data Streams: Real-time big data streaming, efficiently collect and durably store continuous data streams at scale for immediate processing and analysis using Managed Apache Flink(formerly Kinesis Data Analytics)
			- Managed serverless service to collect and store real-time(live) streaming data with low latency from hundreds of thousands of sources(at any scale)
			- Retention of data up to 365 days
			- Couldn't be deleted until expired; with ability to reprocess data by consumers
			- Data is ordered as well as gets on same shard for the same “Partition ID”
			- Producer(Kinesis Agent, AWS SDK)/Client(AWS Data Firehose, Managed Apache Flink, lambda) libraries to write an optimized producer/consumer application
			- for example, for metrics and logs you can install Kinesis Agent on your servers, and it will act as a producer to Kinesis Data Streams
			- Data Stream Capacity Modes;
				1. Provisioned mode:
					- Choose number of shards per consumer with 1 MB/s in (or 1000 records per second) & 2 MB/s out
					- Scale(upto double of the provisioned count) manually to increase/decrease the number of shards
					- Pay per shard provisioned per hour
				2. On-demand mode:
					- Default capacity provisioned(4 MB/s in or 4000 records per second) with auto scalable based on observed throughput peak during the last 30 days
					- Pay per stream per hour & data in/out per GB


		AWS Data Firehose: 
			- Fully managed, serverless, near real-time service with buffer capability(accumulate before sending to target)
			- Load streaming data(with optional transformation using Lambda) to data stores(S3, Redshift, OpenSearch, MongoDB, HTTP endpoint etc.) and analytics tools(Managed Apache Flink)
			- Producers can be; Applications, Client, SDK, Kinesis Agent, CloudWatch, Kinesis Data Stream, AWS IoT
			- Supports CSV, JSON, Parquet, Avro, Raw Text, Binary data
			- Allows conversion of data fromat to Parquet,ORC and compressions with gzip, snappy, zip to save the storage spacce


		AWS MQ
			- SQS, SNS are “cloud-native” services:proprietary protocols from AWS but Traditional applications running from on-premises may use open protocols(MQTT, AMQP, STOMP, Openwire, WSS)
			- When migrating to the cloud, instead of re-engineering the application to use SQS and SNS, we can use Amazon MQ 
			- Managed message broker service for Rabbit MQ, Active MQ and doesn’t “scale” as much as SQS/SNS 
			- Runs on servers, so best practice is to run in Multi-AZ with failover paired with EFS(Multi-AZ mounting ability) storage
			- Amazon MQ has both queue feature (~SQS) and topic features (~SNS)


		AWS SES(Simple Email Service)
			- managed service allows inbound/outbound emails securely(DomainKeys Identified Mail(DKIM) and Sender Policy Framework(SPF)) using APIs or SMTP via application, globally and at scale
			- Flexible IP deployment: shared, dedicated, and customer-owned IPs can be used to send email from specific IP address
			- Provides statistics such as email deliveries, bounces, feedback loop results, open email


		AWS Pinpoint
            - Scalable 2-way(outbound+inbound) segmented personalize marketing communications service via email, SMS, push notification, voice with support of receving replies
			- Use Case: run campaign, bulk transactional SMS message
			- create message templates, delivery schedules, highly-targeted segments; unlike SNS & SES where we need to manage each message's audience, content, and delivery schedule
            - Allows setting automation as reply event can be delivered to Amazon SNS, Kinesis, Data Firehose, and CloudWatch Logs




	Cloud Monitoring
		• Visualize the performance of our cloud deployments

		AWS CloudWatch
			- collect and track metrics, collect and monitor log files, and set alarms for almost all cloud services as well as on-premises servers
			CloudWatch Metrics - for every service in AWS diffreciated via namespaces
				- Monitors CPU-Utilization, Networking mapped with Timestamps and near-real-time delivery to any streaming service(Kinesis) with optional filtering to stram only required
				- We can create CloudWatch dashboards of metrics
				- Up to 30 dimensions(attribute of a metric - instace id, environment, etc.) per metric
				- Important Metrics
					• EC2 instances: CPU Utilization, Status Checks, Network (not RAM)
						- Default metrics every 5 minutes
						- Option for Detailed Monitoring ($$$): metrics every 1 minute
					• EBS volumes: Disk Read/Writes
					• S3 buckets: BucketSizeBytes, NumberOfObjects, AllRequests
					• Billing: Total Estimated Charge (only in us-east-1)
					• Service Limits: how much you’ve been using a service API
					• Custom metrics: we create and push your own metrics
			CloudWatch Alarms
				- Alarms are used to trigger notifications for any CloudWatch metric fall outside thresh-hold(sampling, %, max, min, etc.) limit with 3 status: "OK", "INSUFFICIENT_DATA", "ALARM"
				- Alarms actions for thresh-hold hit;
					• for Auto Scaling : increase or decrease EC2 instances “desired” count
					• for EC2 Actions : stop, terminate, reboot or recover an EC2 instance
					• for SNS notifications : send a notification into an SNS topic
					• for CloudWatch Billing metric : Billing alarm
                - Composite Alarm : Monitoring the status of multiple alarms based on AND and OR conditions
			CloudWatch Logs
				- A single, highly scalable service that centralizes the real-time monitoring of logs from all of your systems, applications, and AWS services
				- Adjustable CloudWatch Logs retention(log expiration policies, 1 day to 10 yrs) even for infinite period of time until used on Lambda, Kinesis, OpenSearch or exported to S3
				- Logs are encrypted by default with ability to use KMS-based encryption with users own keys
				- Collect logs from these services by assigning IAM permissions to the services which will allows these services to send logs in CloudWatch
					• CloudWatch Unified Agent
					• EC2 or on-premises servers : with the help of small hybrid agent SDK(software); CloudWatch log agent(only logs)/CloudWatch Unified Agent(metrics(Disc/RAM/CPU/Network) + logs)
					• Elastic Beanstalk : collection of logs from application
					• ECS : collection from containers
					• AWS Lambda : collection from function logs
					• API Gateway
					• VPC Flow Logs: VPC specific logs
					• CloudTrail based on filter
					• Route53 : Log DNS queries(requests)
				CloudWatch Logs Insight : querying capability within CloudWatch Logs from multiple accounts for creating visualizations, dashboard and exports
				 	• CloudWatch Container Insights : Metrics & logs for ECS, EKS, Kubernetes on EC2, Fargate with the help of containerized version of the CloudWatch Agent
					• CloudWatch Lambda Insights : Detailed metrics to troubleshoot serverless applications
					• CloudWatch Contributors Insights : Find “Top-N” Contributors through CloudWatch Logs
					• CloudWatch Application Insights : Automatic dashboard to troubleshoot your application and related AWS services
                CloudWatch Logs subscription : filter multi account logs to be deliverd to any destination like, Kinesis Data Strams, etc.


		AWS EventBridge(formerly CloudWatch Events)
			- react to events in AWS/3rd party services/custom application, or trigger a rule on a schedule
			- A service that provides a real-time stream of system events fetched from Event Bus based on defined rules, describing changes in resources
			- Allow archiving(indefinitely or defined period) filterd events sent to an event bus(from AWS services, 3rd party services or custom applications) with reply ability
            - Event buses can be accessed by other AWS accounts using resource-based policies
			EventBridge Rules/Sheduler : Cron jobs(Scheduled scripts)


		AWS CloudTrail
			- Defaultly enabled(for All Regions) continuous encrypted logging of AWS accounts activity across multi-region AWS infrastructure into CloudWatch Logs or S3
			- provides event/activity history of AWS account, for actions taken through the AWS Management Console, AWS SDKs, command-line tools, and other AWS services
			- Events Retention upto 90 days in CloudTrail, for longer retention log them to S3 and use Athena for querying in s3 for analysis
			- Allow integration with EventBridge, to send event for specific user activities
			- Provide governance, compliance, operational and risk auditing of AWS accounts
			CloudTrail Insights
				- automated analysis of your CloudTrail Events


		AWS X-Ray
			- End-to-end request tracing: Analyze performance and troubleshoot issues across serverless and distributed applications built using a microservices architecture
			- Advantages;
				• Microservice dependency mapping: Visualize and understand service interactions
				• Performance and error identification: Pinpoint bottlenecks, errors, and exceptions
				• SLA and throttling analysis: Verify service level agreements and identify throttling issues
				• Identify users that are impacted


		AWS Health Dashboard - Global Service
			AWS Service Health Dashboard
				- Shows health status of all AWS services across all regions with historical information for each day
				- provides alerts and remediation guidance when AWS is experiencing events that may impact you
			AWS Account Health Dashboard
				- AWS events that impact specifically your infrastructure


		AWS CodeGuru
			- ML-powered service for automated code reviews and application performance recommendations
			- Provides two functionalities;
				CodeGuru Reviewer : automated code reviews for static code analysis (development)
				CodeGuru Profiler : visibility/recommendations about application performance during runtime (production)




	Cloud Networking
		• IP Addresses in AWS
			- IPv4 : Internet Protocol version 4 (4.3 Billion Addresses)
				- All public IPv4(255.255.255.255) on AWS will be charged $0.005 per hour(includes Elastic IP as it is public ip)
				• Public IPv4
					- used on the Internet, i.e. must be unique across whole web
					- By default, EC2 instance gets a new a public IP address every time you stop and start again
				• Private IPv4
					- Used on private networks(LAN) such as internal AWS networking(e.g. 192.168.1.1)
                    - must be unique within a private network, but two different private networks can have the same IP addresses
					- Private IPv4 is fixed for EC2 Instances even if you start/stop them
                    - To connect to the internet from a private network, we can use NAT and Internet Gateway(proxy)
				• Elastic IP 
					- allows you to attach a fixed public IPv4 address to one EC2 instance at a time
                    - By default, max 5 Elastic IP per region per account(can be increased by communicating with AWS)
                    - try to avoid using Elastic IPs as they often reflect poor architectural decisions. 
                    - Instead, use a random public IP and register a DNS name to it. Or, follw best practice using a Load Balancer eliminating use of public IP
			- Monitor pulic IP address in use : "Amazon VPC IP Address Manager" -> "Public IP insights"

			- IPv6 : Internet Protocol version 6 (3.4 × 10!" Addresses)
				• Every IP address is public in AWS (no private range)
				• Example IPv6 address: 2001:db8:3333:4444:cccc:dddd:eeee:ffff
				• Newer, to solve the problems for IoTs
				• Free to use/expose services on internet

		• Classic ports to know
			21 = FTP(File Transfer Protocol) - upload files into a file share
			22 = SFTP(Secure File Transfer Protocol)
			80 = HTTP(Hypertext Transfer Protocol) - access unsecured websites
			433 = HTTPS(Hypertext Transfer Protocol Secure) - access secured websites
			22 = SSH(Secure Shell) - log into a Linux instance
			3389 = RDP(Remote Desktop Protocol) - log into a windows instance


		AWS VPC(virtual private cloud)  - Regional resource
			- private virtual network to deploy your resources dedicated to your AWS account in specific region
			- Default IPs addresses range that are allowed within default VPC(Auto-created for new AWS accounts): 172.31.0.0/16  => 172.31.0.0 - 172.31.255.255;  65,536 IP addresses

			Subnet  - AZ specific resource
				- allow you to partition your network inside your VPC according to Availability Zones 
				- In default VPC all subnets are public
				- Partition services on;
					• public subnet is accessible from the internet using route to the Internet Gateways of VPC - used for Load Balancer, EC2, etc.
					• private subnet is not accessible from the internet - used for RDS, etc.
						- Use NAT Gateways(AWS-managed) & NAT Instances(self-managed) for instances in private subnet that need access to Internet for OS updates, file downloading, etc. 
						- for Internet connectivity, create a route from the private subnets to the NAT Gateway, and from the NAT Gateway to the Internet Gateway

			Internet Gateway
				- VPC can only have one Internet Gateway 
				- for instances in public subnet to get accessed from/to Internet

			Network Address Translation(NAT) Gateways(AWS-managed)/NAT Instances(self-managed)
				- for instances in private subnet that need access to Internet while still remaining private
                - allows multiple devices on a private network to share a single public IP address for internet access

			Route Tables  
				- To define access to the internet and between subnets, we use Route Tables

			Elastic Network Interface(ENI) - AZ specific resource
				- Logical component that represents a virtual network card within a particular subnet(AZ) of the VPC. i.e. can't attach to an EC2 instance in a different AZ
				- ENI could be created independently and attached to EC2 instances for failover within a particular subnet(AZ) of the VPC.
				- ENI attributes;
					• MAC address
					• Single primary static private IPv4 that gets created/deleted with the resource(EC2 instance)
					• Multiple secondary private IPv4
					• could have single elastic or public IPv4 per private IPv4
					• Can have multiple security groups attached to ENI 
					• "Delete on Termination" Flag
					• Source/Destination Check enabled by default, i.e. instance with private IPv4 NATs the request to internet using Elastic IPv4 and vice versa for response from the Internet to Instance

			Network security
				- by allowed/deny inbound/outbound traffic
				- Two types;
					• Network ACL(subnet level) ; Stateless, Firewall which controls inbound/outbound subnet traffic 
					• Security Groups(instance level) ; Statefull Firewall that controls traffic to/from an EC2 Instance

			Flow Logs
				- Helps to monitor filterd IP traffic going into your interfaces & troubleshoot connectivity issues 
				- Also Captures network information from AWS managed interfaces. like, Elastic Load Balancers, ElastiCache, RDS, Aurora, etc.
				- logs data can go to S3, CloudWatch Logs, and AWS Data Firehose

			Peering Connections
				- Connect two VPC privately using AWS network to behave as if they were in the same network
				- Must not have overlapping CIDR (IP address range)
				- Peering connection must be established for each VPC that need to communicate with one another. i.e. vpcA ⇄ vpcB | vpcA ⇄ vpcC | vpcB ⇄ vpcC

			Endpoints
				- allow you to connect to AWS Services from VPC using a private network instead of the public www network, with enhanced security and lower latency
				- Types
					• VPC Endpoint Gateway: for only S3 & DynamoDB 
					• VPC Endpoint Interface(ENI): most services(including S3 & DynamoDB)
				AWS PrivateLink
					- To privately connect service running within your VPC to other VPC on other account directly, without requiring VPC peering, internet/NAT gateway, route tables
					- Requires a network load balancer(Service/accessed VPC) and ENI(Customer/accessing VPC)

			Hybrid VPC
				- To connect on-premises data center to the VPC
				- Two options;
					• Site to Site VPN
						- Connect an on-premises(using Customer Gateway-CGW) VPN to AWS VPC(using Virtual Private Gateway-VGW) 
							On-premise DataCenter ⇄ CGW   ==(public WWW)==>   Site to Site VPN(Encrypted)   ==(private AWS)==> VGW ⇄ VPC
						- The connection is automatically encrypted.
						- Goes over the public internet so it will have limited bandwidth and security concerns
					• Direct Connect (DX)
						- Establish a physical connection between on-premises and AWS
						- Goes over a private network so connection is private, secure, fast and reliable
						- Costlier and takes at least a month to establish

			AWS Client VPN
				- Connect from your computer using AWS Client VPN(OpenVPN) to your private network in AWS and on-premises
				- Allow you to connect to your EC2 instances over a private IP (just as if you were in the private VPC network)
 				- connection goes over public Internet

			Transit Gateway
				- One single Gateway to provide peering between thousands of VPC, on-premises DC(Direct Connect Gateway), VPN connections in star topology

		CloudFront and Route 53:
			- Ensures availability using global edge network
			- Combined with AWS Shield, provides attack mitigation at the edge




	Security & Compliance		
		• OSI Model									 TCP/IP Model
			7. Application Layer					 ↱  4. Application Layer
			6. Presentation Layer					 |
			5. Session Layer						 |
			4. Transport Layer						    3. Transport Layer
			3. Network Layer						    2. Internet Layer
			2. Data Link Layer						 ↱  1. Network Access Layer (or Link Layer)
			1. Physical Layer						 |	


		AWS Shield Standard: 
			- Free service that is activated by default for every AWS customer
			- protects only against DDOS(Distributed Denial of Service - SYN/UDP Floods), Reflection attacks and other layer 3/layer 4 attacks for your website and applications


		AWS Shield Advanced: 
			- Optional DDoS attack protection service to mitigate layer 7 attacks automatically with costs about $3,000 per month per organization
			- Protect against more sophisticated attack on Amazon EC2, Elastic Load Balancing (ELB), Amazon CloudFront, AWS Global Accelerator and Route 53
			- 24/7 access to AWS DDoS response team (DRP) with protection against higher usage fee incured during traffic spikes due to DDoS


		AWS WAF(Web Application Firewall) (Regional Resources; except ACM defined globally if deployed on CloudFront) 
			- inspects web requests coming into your application(Application Load Balancer, API Gateway, CloudFront) and filters requests based on rule groups
			- Rule group is a reusable set of rules that you can add to a web ACL
			- protect web applications from common web exploits that may affect availability, compromise security, or consume excessive resources
			- Defined on Application Layer(HTTP/HTTPS)
			- Web ACL(Web Access Control List) : web access control lists, and their rules
				• Rules can include IP addresses, HTTP headers, body, or URI strings to Protects from common attack like, SQL injection and Cross-Site Scripting(XSS)
				• Protects from common attack - SQL injection and Cross-Site Scripting (XSS)
				• Size constraints(eg. max 2 KB request), geo-match (to block request from specific countries)
				• Rate-based rules (to count occurrences of events); for DDoS protection


		AWS Network Firewall
			- Protect your Amazon VPC inbound and outbound traffic from network/internet layer to top(application layer)


		AWS Firewall Manager
			- Centrally manage security rules across all AWS accounts in your AWS Organization
			- Rules in Firewall Manager going to be applied to all the current and future accounts, for all the security policy applied resources as they are being created in these accounts
			- Security policy region level set of security rules for;
				• VPC Security Groups (for EC2, Application Load Balancer, ENI resources in VPC)
				• WAF rules (for ALB, CloudFront, API Gateway)
				• AWS Shield Advanced (for ALB, CLB, NLB, Elastic IP, CloudFront)
				• AWS Network Firewall (at VPC level)
				• Route 53 Resolver DNS Firewall rules


		AWS Penetration Testing
			- We can perform security assessments or penetration tests against AWS infrastructure without prior approval
			- currently for 8 services(List can increase over time)
				• Amazon EC2 instances, NAT Gateways, and Elastic Load Balancers
				• Amazon RDS
				• Amazon CloudFront
				• Amazon Aurora
				• Amazon API Gateways
				• AWS Lambda and Lambda Edge functions
				• Amazon Lightsail resources
				• Amazon Elastic Beanstalk environments
			- Prohibited Activities
				• DNS zone walking via Amazon Route 53 Hosted Zones
				• Denial of Service (DoS), Distributed Denial of Service (DDoS), Simulated DoS, Simulated DDoS
				• Port flooding
				• Protocol flooding
				• Request flooding (login request flooding, API request flooding)


        AWS Flult Injection Simulator(FIS)
            - Managed service for running fault injection experiments(stress application using disruptive events.eg. sudden usage spikes) using pre-built templates on the AWS workloads
            - helps to uncover hidden bugs & performance bottlenecks for EC2, ECS, EKS, RDS, etc.


		AWS KMS(Key Management Service) (Regional Resource)
			- Managed service to manage encryption keys with seamlessly integration to EBS, S3, RDS, SSM, etc.
			- To restrict kms key access/cross account access, we could define "KMS Key Policy" without which we cannot access kms keys
			- Multi-Region KMS Keys
				• KMS Multi-Region key(MRK) have the same key ID/material but are NOT global(Primary + Replicas), i.e. each Multi-Region key need to be managed independently
				• Use cases: Encrypt in one Region and decrypt in other Regions; global client-side encryption, encryption on Global DynamoDB/Aurora
			- Types of AWS KMS Keys;
				• Customer Managed Key:
					- Create, manage and used by the customer, can enable or disable
					- Allow key rotation policy(eg. new key generated for every 90-2560 days, prserving old key)
					- Allows to bring-your-own-key
					- costs : $1 per month per key + $0.03 per 10000 API calls to KMS
				• AWS Managed Key:
					- Created, managed and used by AWS on the customer’s behalf with automatic key rotaion for every 1 year
					- Used by AWS services (aws/s3, aws/ebs, aws/redshift)
					- Free to use
				• AWS Owned Key:
					- Collection of CMKs that an AWS service owns and manages to use in multiple accounts. eg. SSE-S3, SSE-SQS, SSE-DDB (default key)
					- AWS can use those to protect resources in your account (but you can’t view the keys)
					- Free to use
				• CloudHSM Keys (custom keystore):
					- Keys generated from your own CloudHSM hardware device
					- Cryptographic operations are performed within the CloudHSM cluster
			KMS Custom Key Store : CloudHSM(Hardware Security Module)
				- AWS only provisions encyption hardware(HSM) but encryption keys management is users/customers responsibility
				- HSM device is tamper resistant, and security standard: FIPS 140-2 Level 3 compliance


		AWS Certificate Manager (ACM) (Regional Resource)
			- Provision, manage, and deploy SSL/TLS(public-private) certificates used to provide in-flight traffic encryption for websites providing an HTTPS(http with SSL/TLS handshake) endpoints
			- Free of charge for ACM provided public TLS certificate including automatic certificate renewal feature after every 60 days
			- Integrations with(i.e. loads TLS certificates on);
				• Elastic Load Balancers(X.509 certificate)
				• CloudFront Distributions
				• APIs on API Gateway
				• Create upload users own certificates
				Note - cannot use ACM with EC2
			- SSL(Secure Socket Layer)/TLS(Transport Layer Security) is secret handshake(encryption + Trust) between client and server to create private, encrypted tunnel before communication
			- Certificates are digitally signed & issued by trusted Certificate Authorities(CA) like; Symantec, GoDaddy, Letsencrypt, etc. with expiration time that's why certificates must be renewed
			- When setting an HTTPS listener, 
				• Must specify a default certificate
				• Add an optional list of certificates to support multiple domains
				• Clients can use SNI(Server Name Indication) to specify the hostname
					SNI - Let clients tell the server which domain it’s reaching before a secure connection so that Server knows exactly which SSL/TLS certificate to send, 
						  SNI allows multiple SSL certificates to be loaded on single server for multiple domains hosting on single server(12.134.123.44) -> a.com(certA), b.com(certB)


		AWS Secrets Manager
			- Secrets storing service with capability to force rotation of secrets every N days with automated generation of secret on rotation using lambda functions
			- Secret to be managing in RDS credentials with ability of encryption using KMS
			- Replicate Secret(Multi-Region) : Allow replication of Secrets across multiple AWS Regions with auto sync read replicas of primary secret
			- Pricing:
				• $0.40 per secret per month
				• $0.05 per 10,000 API calls


		AWS Artifact -  Global resource (not really a service)
			- Provides on-demand access to AWS compliance documents and agreements which are used to support internal audit or compliance
			- Artifact Reports - Allows you to download AWS security/compliance reports from third-party auditors, like AWS ISO certifications, Payment Card Industry (PCI), and System and Organization Control (SOC) reports
			- Artifact Agreements - Allows you to review, accept, and track the status of AWS agreements such as the Business Associate Addendum (BAA) or the Health Insurance Portability and Accountability Act (HIPAA) for an individual account or in your organization


		Amazon GuardDuty
			- Intelligent threat discovery using Machine Learning algorithms, anomaly detection, 3rd party data to protect your AWS Account
			- No need to install software, One click to enable (30 days trial), 
			- Find malicious behavior using;
				• CloudTrail Events Logs - unusual API calls, unauthorized deployments
					- CloudTrail Management Events - create VPC subnet, create trail, etc.
					- CloudTrail S3 Data Events - get object, list objects, delete object, etc.
				• VPC Flow Logs - unusual internal traffic, unusual IP address
				• DNS Logs - compromised EC2 instances sending encoded data within DNS queries
				• Optional Features - EKS Audit Logs, RDS & Aurora, EBS, Lambda, S3 Data Events, etc.
			- Send GuardDuty founding to EventBridge rules which can target AWS Lambda or SNS
			- Can protect against CryptoCurrency attacks (has a dedicated “finding” for it)


		AWS Inspector
			- Allow to run Automated Security Assessments(find software vulnerabilities) only for evaluation of EC2 instances, Container Images & Lambda functions
			- For EC2 instances
				• Leveraging the AWS Systems Manager (SSM) agent
				• Analyze against unintended network reachability
				• Analyze the running OS against known vulnerabilities
			- For Container Images push to Amazon ECR
				• Assessment of Container Images as they are pushed
			- For Lambda Functions
				• Identifies software vulnerabilities in function code and package dependencies
				• Assessment of functions as they are deployed
			- Package/dependencies vulnerabilities(EC2, ECR & Lambda) and database of CVE(Common Vulnerabilities and Exposures)
			- Continuous scanning of the infrastructure, only when needed
			- Reporting & integration with AWS Security Hub
			- Send findings to Amazon Event Bridge with risk score associated for all vulnerabilities for prioritization


		AWS Config (Regional Resource)
			- Record configuration changes over time of your AWS resources based on compliance rules (AWS managed or custom defined in Lambda)
			- Possibility of storing the configuration data into S3(to be analyzed by Athena) or receiving alerts using SNS notifications
			- Questions that can be solved by AWS Config:
				• Is there unrestricted SSH access to my security groups?
				• Do my buckets have any public access?
				• How has my ALB configuration changed over time?
			- Pricing : $0.003 per configuration item recorded per region, $0.001 per config rule evaluation per region
			AWS Config Remediation : automatically re-configure non-compliant resources using SSM Automation Documents with reply(upto 5 times) capability
			AWS Config Resource
				- View compliance of a resource over time
				- View configuration of a resource over time
				- View CloudTrail API calls if enabled


		AWS Macie
			- Managed data security and data privacy service that uses machine learning and pattern matching to discover and protect your sensitive data in AWS(s3)
			- Macie helps identify and alert you to sensitive data, such as personally identifiable information(PII)


		AWS Security Hub
			- Central security tool to manage security across multiple AWS accounts and automate security checks
			- Must first enable the AWS Config Service
			- Integrated dashboards showing current security and compliance status to quickly take actions
			- Automatically aggregates alerts in predefined or personal findings formats from various AWS services & AWS partner tools:
				• AWS Config
				• AWS GuardDuty
				• AWS Inspector
				• AWS Macie
				• IAM Access Analyzer
				• AWS Systems Manager
				• AWS Firewall Manager
				• AWS Health
				• AWS Partner Network Solutions
			- anytime there's a security issue this is going to generate an event in EventBridge and to investigate the source of these issues you can use Amazon Detective 


		Amazon Detective
			- Analyzes, investigates, and quickly identifies the root cause of security issues or suspicious activities (using ML and graphs) 
			- Automatically collects and processes events from VPC Flow Logs, CloudTrail, GuardDuty to create a unified visualizations with details and context


		AWS Abuse
			- Report suspected AWS resources used for abusive or illegal purposes
			- Abusive & prohibited behaviors are:
				• Spam - receving undesired emails from AWS-owned IP address, websites & forums spammed by AWS resources
				• Port scanning - sending packets to your ports to discover the unsecured ones
				• DoS or DDoS attacks - AWS-owned IP addresses attempting to overwhlem or crash your servers/softwares
				• Intrusion attempts - logging in on your resources
				• Hosting objectionable or copyrighted content - distributing illegal or copyrighted content without consent
				• Distributing malware - AWS resources distributing softwares to harm computers or machines
			- Contact the AWS Abuse team: AWS abuse online form, or abuse@amazonaws.com


		IAM Access Analyzer
			- Find out which resources are shared externally(Access outside zone of trusts) and provides findings
				• S3 Buckets
				• IAM Roles
				• KMS Keys
				• Lambda Functions and Layers
				• SQS queues
				• Secrets Manager Secrets
			- Define Zone of Trust = AWS Account or AWS Organization
			- Free to use




	Deploying and Managing Infrastructure at Scale Section
		AWS CloudFormation
			- declarative way(JSON/YAML) of outlining your AWS Infrastructure(no need to figure out ordering and orchestration)
			- model and provision resources needed for an application leveraging user account permissions(default) or optional service role(cloudformation dedicated IAM role)
					User(IAM Permissions : cloudformation:*, iam:PassRole)  ->  Template  ->  CloudFormation(Service Role : s3:*Bucket)
			- CloudFormation creates/deletes your declarations for you, in the right order, with the exact configuration that specified(for creation)/needed(for deletion)
			- Ability to destroy and re-create an infrastructure on the cloud automatedly for cost optimization
			- Supports almost all AWS resources, allowing use of "custom resources" for resources that are not supported
			- Used for : Infrastructure as code; repeating same architecture across environments, regions, or AWS accounts.
			AWS Infrastructure Composer
				- visualize/create Cloudformation teeplate(all the resources & relations between the components;design and build serverless applications)


		AWS Cloud Development Kit(CDK)
			- Define your cloud infrastructure using a familiar language: JavaScript/TypeScript, Python, Java, and .NET
			- The code is “compiled” into a CloudFormation template (JSON/YAML)
			- Deploy infrastructure and application runtime code together
			- CDK Application(Pytnon/JS/Java/...)  -->  CDK CLI  -->  CloudFormation Template  -->  CloudFormation
			- CDK code example(JS);
					export class MyEcsConstructStock extends core.Stack {
						constructor(scope: core.App, id: string, props?: core.StackProps){
							super(scope, id, props);

							const vpc = new ec2.vpc(this, "Myvpc", {
								maxsize: 3 // Default is all AZs in region
							});

							const cluster = ne2 ecs.Cluster(this, "MyCluster", {
								vpc: vpc
							});

							// Create a load-balanced Fargate service and nake it public
							new ecs_patterns.ApplicationLoadBalancedFargateService(this,"MyFargate",{
								cluster: cluster, 	// Required
								cpu: 512, 			// Default is 256
								desiredCount: 6, 	// Default is 1
								taskImageOptions:  {image: ecs.ContainerImage.fromRegistry("an")}
								memoryLimitMiB: 2048, 		// Defoult is 512
								publicLoadBalancer: true 	// Defoult is false
							});
						}
					}


		AWS Elastic Beanstalk
			- Managed Platform as a Service : Developers responsibility is only application code 
			- Beanstalk automatically(leveraging CloudFormation) handles;
				• Deployment (strategy is fully configurable)
				• Instance configuration/OS
				• Capacity provisioning
				• Load balancing & auto-scaling
				• Application health-monitoring & responsiveness
			- Beanstalk is free but user only pay for the underlying instances/services provisioned
			- components;
				• Application : collection of Elastic Beanstalk components(environments, versions, configurations, etc.)
				• Application Version : an iteration of your application code
				• Environment :
					- Collection of AWS resources running an application version(only one application version at a time)
					- Environment Tiers : Web Server Environment(dev, test, prod, etc.) Tier & Worker Environment Tier(scaling based on Number of SQS messages)
			- Support for many platforms :
				• Go, Java SE, Java with Tomcat, Node.js, PHP, Python, Ruby, .NET on Windows Server with IIS
				• Packer Builder
				• Single/Multi Container or pre-configured Docker
			- Three architecture models :
				• Single Instance deployment : good for dev environment
				• LB + ASG : great for production or pre-production web applications
				• SQS + ASG : great for non-web apps in production (workers, etc.)


		AWS CodeDeploy (Hybrid Service - either used on AWS(EC2 Instances) and On-premises infrastructures)
			- Automates application deployments with:
				• EC2 Instances
				• On-Premises Servers
			- Servers/Instances must be provisioned and configured ahead of time with the CodeDeploy Agent
            - Avoids downtime during deployment


		AWS CodeArtifact
			- Secure, scalable, and cost-effective artifact(software packages and code-dependencies) management for software development
			- Developers and CodeBuild can then retrieve dependencies(such as Maven,Gradle,npm,yarn,twine,pip and NuGet) straight from CodeArtifact


		AWS CodeCommit - Deprecation(On July 25th 2024)
			- AWS abruptly discontinued CodeCommit. New customers cannot use the service
			- Source-control service that hosts Git-based private repositories(version controlled), Makes it easy to collaborate with others on code, with automatically versioned
			- AWS recommends to migrate to an external Git solution


		AWS CodeBuild
			- Fully managed, serverless, Continuously scalable & highly available, Secure
			- Compiles code, runs tests, creates deployable packages.
			- Pay-per-build-minute pricing. i.e. only pay for the build time.


		AWS CodePipeline
			- Orchestrate the code, build, test, and deployment stages; insuring fast delivery & rapid updates
				• Code => Build => Test => Provision => Deploy => provisioning  ||  CodeCommit => CodeBuild => CodeDeploy => Elastic Beanstalk
				• Basis for CICD (Continuous Integration & Continuous Delivery)
			- Fully managed, compatible with CodeCommit, CodeBuild, CodeDeploy, Elastic Beanstalk, CloudFormation, 3rd-party services (GitHub) & custom plugins


		AWS Systems Manager(SSM) (Hybrid Service - manage your AWS(EC2) and On-Premises systems at scale)
			- Get operational insights about the state of your infrastructure by installing the SSM agent(small program)
			- SSM agent(small program) is defaultly available on Amazon Linux AMI & some Ubuntu AMI on AWS
			- Out of many, the most important features are:
				• Patching automation for enhanced compliance
				• Run commands across an entire fleet of servers
				• Store parameter configuration & secrets with the SSM Parameter Store with encryption Possibility
				• Works for Linux, Windows, MacOS, and Raspberry Pi OS (Raspbian)
            - Automation RunBook : Pre-defined SSM document(instructions) for specific action. like; restart all the EC2 instances, Take snapshots of all RDS
            
			SSM Session Manager 
                - connect to EC2 instance by adding IAM role to EC2 instance for accessing AWS SSM
                - Allows you to start a secure shell on your EC2 and on-premises server without SSH access enabled(port 22 opening), bastion hosts, or SSH keys needed
                - Allows invoking using EventBridge Send session log data to S3 or CloudWatch Logs and notification to SNS about command status
            
			AWS SSM Parameter Store
                - Secure storage for configuration and secrets(API Keys, passwords, configurations, etc.)
                - Serverless, scalable, durable(respond to many API calls all the time), easy SDK
                - Access control to each parameter in the parameter store using IAM
                - Allow Version tracking & KMS encryption
				- Parameter Store tiers;
					1. Standard
						- 10,000 number of parameters allowed(per AWS account and Region)
						- Maximum size of 4 KB for a parameter value
						- Free for use/parameter storage
					2. Advanced
						- 1,00,000 number of parameters allowed(per AWS account and Region)
						- Maximum size of 8 KB for a parameter value
						- charges applied per key & for kye storage with $0.05 per advanced parameter per month
						- Also comes with ability to set Parameter Policy to assign a TTL to a parameter(expiration date) to force updating or deleting sensitive data such as passwords


		AWS Amplify
			- A set of tools and services that helps you develop and deploy scalable full stack web and mobile applications
			- Authentication, Storage, API(REST, GraphQL), CI/CD, Pub-Sub, Analytics, AI/ML Predictions, Monitoring, Source Code from AWS, GitHub, etc.
			AWS AppSync
				- Store and sync data across mobile & web apps in real-time using GraphQL(mobile technology from Facebook) in which client Code can be generated automatically
				- Allows integrations with DynamoDB/Lambda
				- Real-time subscriptions/sync(because of GraphQL backend)
				- Offline data synchronization(replaces Cognito Sync)
				- Fine Grained Security




	Compute
		AWS EC2(Elastic Compute Cloud) - IAAS/Local Service (AZ specific resource)
			- Rent virtual machines (EC2)
			- Storing data on virtual drives (EBS)
			- Distributing load across machines (ELB)
			- Scaling services using auto-scaling group (ASG)

			EC2 sizing/configuration options -
				- OS (Linux, Windows or Mac OS)
				- CPU (Computer Power and Cores)
				- RAM
				- Storage Space
					- Network Attached (EBS & EFS)
					- Hardware Attached (EC2 instance store)
				- Network Card
				- Firewall rules (Security group)
				- Bootstrap Script (configure at only first launch - EC2 user data) Automates the installation steps
						// Bootstrapping means launching commands in root access when the machine starts to handle boot tasks which includes   
											- installing updates/software
											- downloading common files from internet
			EC2 Instances Type
				- General Purpose (M T) e.g. m5.2xlarge   - m(General Purpose Instance Class), 5(generation), 2xlarge(memory, CPU of Instance)
				- Compute Optimized (C)
				- Memory Optimized (R U X)
				- Accelerated Computing (DL F G P)
				- Storage Optimized (D H I)
				- High-performance computing (HPC)

			Security Groups - Regional resource
				- network security of EC2(s) which controls how traffic is allowed inbound or outbound of our EC2 instances
				- by default, all INBOUND traffic is BLOCKED, and all OUTBOUND traffic is AUTHORISED
				- it's good to maintain one separate security group for SSH access.
				- we can refer another/multiple security group in new/one security group

				note - if application is not accessible due to (time out), then it's most likely a security group issue

			EC2 accessing Options - 
				1. SSH(Secure Shell/Secure Socket Shell) - by opening inbound port 22 and use SSH keys with terminal
						- refers to the cryptographic network protocol and to the suite of utilities that implement that protocol.
						- used to connect inside of your servers to perform some maintenance or action.
						- SSH is widely used by network administrators to manage systems and applications remotely using cmd

						Command to enter SSH in AWS EC2 Instance -
						> ssh -i <ppm file location> ec2-user@<Public IPv4 address>            // > ssh -i .\first-instance.pem ec2-user@35.154.197.67

				2. EC2 Instance Connect -	by opening inbound port 22; don't need SSH key

				3. AWS Session Manager - by adding IAM role to EC2 instance for AWS Systems Manager
						- Allows you to start a secure shell on your EC2 and on-premises server without SSH access enabled(port 22 opening), bastion hosts, or SSH keys needed
						- Send session log data to S3 or CloudWatch Logs

			EC2 Purchasing Option
				- On-Demand - short-term un-interrupted workload, predictable pricing, pay by second
                    • Pay per second (Linux/Windows) or per hour (other) and price is fixed
					• Minimum billing time of 60 sec
				- Reserved(1 to 3 years) 
                        1. Reserved Instance - long workload, reserve a specific instance attribute(i.e. instance type, Region, OS, tenancy(Host,Dedicated,default))
                        2. Convertible Reserved Instance - long workload with flexible instances, change instance attributes
                    • 1 to 3-years commitment for EC2 instance
                    • All upfront(most discount), partial upfront, no upfront
                    • Up to 75% discount compared to On-demand on hourly rate
				- Savings Plans - minimum committed amount of usage, locked instance family & AWS region but size flexible(micro,small)
                    • Better alternative to Reserved Instances
                    • Commit to $10/hour for three years on C5 instances in a region regardless of AZ, size(m5.xl to m5.4xl), OS(Linux/Windows) or tenancy(shared/dedicated host)
				- Spot Instances - cheapest, lose instance because of bid; short & failure resilient workload
                    • Bid for unused capacity in EC2 instances
						- Up to 90% discount compared to On-demand on hourly rate
						- Defining Spot Request:
                            • Request type;
                                One-time : as soon as instances launched, Spot request will get terminated
                                Persistent : Spot request continues to capture instances for valid from/valid until
                            • MAX spot price; capture instance while (CURRENT spot price < defined MAX spot price); as hourly spot price varies based on offer and capacity
                            • Desired number of Instances
                            • Launch Specification(AMI)
                            • Valid from/valid until(could be infinite)
                        - We get 2 min of grace period to stop(reserving state to use again : Persistent Spot Request) or terminate(One-time Spot Request) instances
                        - Cancelling open, active or disabled Spot Requests does not terminate captured instances
                        - For stoping/terminating spot instances. first, we must cancel associated Persistent Spot request to avoid relaunching
                        - Well-suited for data analysis, batch jobs, background processing, optional tasks or workloads that are resilient to failures; not suitable for critical jobs		
				- Spot Fleets - set of Spot Instances and optionally On-demand Instances allows you to automatically request Spot Instances with the lowest price
                    • Auto launching set of Spot Instances(with the lowest price) and optionally On•demand Instances to meets the target capacity/count with price constraints(max cost)
                    • Strategies to allocate/launch Spot Instances:
                        - lowestPrice: launch spot instances from the pool(instance type(m5.large), OS, AZ) with the lowest price; for, cost optimisation, short workload
                        - diversified: launching spot instances which are distributed across all pools(ensuring availability); great for relatively long workloads
                        - capacityOptimized: launching spot instances from pool with the optimal capacity for the number of instances
                        - priceCapacityOptimized(recommended): Selects the Instance pool with the lowest price from the choosen pools with highest capacity available, best for most workloads        
				- Dedicated Hosts - most expensive, books entire physical server, gives lower level hardware access, good for companies with high compliance needs or use own software licenses
                    • Physical server fully dedicated for your use
                    • Reservation for 1 year or 3 years commitment
                    • allows you to use your eligible software licenses from vendors such as Microsoft and Oracle on Amazon EC2
				- Dedicated Instances - instance running on dedicated hardware, no control over instance placement 
				- Capacity Reservation - reserved in specific AZ for any duration, no matter you use or not you have to pay all, short-term un-interrupted workload

			EC2 Placement Groups
				- control(without direct hardware interaction) over EC2 instances placement compared to one another within the AWS infrastructure
				- placement strategies;
					• Cluster(for high performance and low network latency, but has high risk due to AZ failure) : grouping instances into low-latency hardware setup in single AZ
					• Spread(for availability, not scalability) : spreads instances across different AZ, max 7 instances per group per AZ
					• Partition(for scalability) : groups instances across multiple(max 7) different failure isolated partitions(set of server racks) within one or across multiple AZ
						Note : Partition or set of server racks; specific details can be accessed by instance metadata

			EC2 Storage
                Block Storage
                    Elastic Block Store(EBS) Volumes (AZ specific resource - To access in other AZ/other Regions AZ we can use snapshot(back-up) and restore in that AZ/Regions AZ)
                        - Isolated network drive(not physical) attached to only one running instance at a time (except "multi-attach" in same AZ for io1/io2 EBS Volumes)
                        - Multiple EBSs can be attached to single instance, as well as EBS can be left unattached
                        - Persists data even after instance termination, which is managed by "Delete on Termination" flag.
                        - Allows to use provisioned capacity and performance - size in GB and IOPS(I/O operation per second)
                        - Enables EC2 instance Hibernation(preserves RAM(max 150 GB) state only in encrypted root EBS volume for max 60 days)
                        - pricing(I/O operation per second - performance of volume);
                            • Volume type: (based on performance)
                                1. GP2/GP3 				 : General purpose SSD volume that balances price and performance for a wide variety of workloads
                                2. io1/io2 Block Express : Highest-performance SSD volume for mission-critical low-latency and high-throughput workloads
                                3. st1 					 : Low cost HDD volume designed for frequently accessed, throughput intensive workloads
                                4. sc1 					 : cheapest HDD volume designed for less frequently accessed workloads
                                Note : only GP2/GP3 and io1/io2 SSD Block Express can be used as boot volumes, that means root OS running on these volumes only
                            • Size of storage volume in GB per month provisionned(eg. 100 GB), regardless of if used or not
                                - GP2/GP3 : 1 GB to 16 TB
                                - io1/io2 : 4 GB to 64 TB
                                - st1/sc1 : 125 GB to 16 TB
                            • IOPS(I/O operation per second):
                                - General Purpose SSD: GP2/GP3 has 3,000-16,000 IOPS and throughput of 125-1000 MB/s
                                - Provisioned IOPS(PIOPS) SSD: io1/io2 has max 2,56,000 IOPS(EC2 Nitro Instance), supports multi-attach(max 16 instances, cluster-aware file system is must), used for DB workloads needing better IOPS and consistency
                                - st1: Throughput optimized, max 500 IOPS and throughput of 500 MB/s, used for Big Data, Data Warehousing, Log Processing, etc.
                                - sc1: Cost Optimized, max 250 IOPS and throughput of 250 MB/s, used for infrequently accessed data with lowest storage cost
                                - Magnetic(Standard): Number of requests
                            • Snapshots:
                                - Added data cost per GB of snapshot per month
                            • Data transfer:
                                - Inbound is free
                                - Outbound data transfer are tiered for volume discounts
                        EBS Snapshot
                            • Backup of EBS volume in any AZ or Regions at any point of time with no need of detachment(but recommended to detach first to get best performance)
                            • Allows recovery from Recycle Bin for EBS snapshot deletion(for accidental deletion) with specified retention period(from 1 day to 1 year)
                            • EBS Snapshot Archive(upto 75% cheaper) : allows automatic movement to archival tier as well as manual moving, but restoring will takes 24 to 72 hours
                            • Fast Snapshot Restore(FSR) : By paying extra, force full initialization of snapshot to EBS volume for low-latency instance launching
                        EBS Encryption
                            • Managed encryption, handled by AWS(using KMS(AES-256) keys) with very negligible latency impact after you created encrypted EBS volume from encrypted snapshot
                            • Data at rest inside volume, data in-flight of EBS and EC2, all snapshot only from encrypted EBS and all volume created with any snapshot are/may be encrypted
                            • Any Snapshots created from non-encrypted EBS volume won't be encrypted; to encrypt snapshot we can use copy snapshot feature

                    EC2 Instance Store(local)
                        - Temporary(wiped out in case of stop/terminate/failure of VM instance) block-level storage physically attached to a virtual machine/instance
                        - No additional cost beyond the cost of the instance. But, size, number and type(HDD or SSD) available depend on the specific instance type you choose
                        - Higher I/O performance(IOPS of 3,10,000) and high disk performance as High performance disk physically attached to instance, rather than networkly attached EBS volume
                        - Risk of data loss if hardware fails, so Backup and Replication should be users responsibility
                        - Ideal for volatile data; buffer, cache, temp data
                
                Network File System Storage
                    Elastic File System(EFS) - managed(auto scalable) network file system (Multi-Availability Zone storage)
                        - can be mounted on 1000s of instances(with Linux based AMI, not Windows) in different AZs using EFS Mount Target with controlled access via security group
                        - auto scalable(1000 concurrent NFS clients with 10+GB/s throughput), highly expensive(3x than GP2 EBS volume)
                        - provides a POSIX file system interface, and concurrently-accessible storage for up to thousands of Amazon EC2 with only Linux(POSIX system) instances 
                        - Pricing; pay per use(per GB used), has One-Zone(single AZ) FS type & lifecycle policies feature for upto 90% cost saving
                        - Storage Tier: Lifecycle Policies feature to move files after n days for cost
                            • Standard : for frequently accessed files
                            • EFS-IA(Infrequent Access) : cost-optimized storage class to save cost for storing files not accessed frequently
                            • Archive : rarely(few times a year) accessed data, 50% cheaper

                    AWS FSx(File System x)
						- Fully managed third-party file system service optimized for high-performance file systems with Multi-AZ feture on AWS 
						- Allowing to be accessed from On-premises infrastructure(VPN or Dorect Connect)
						- Data is backed-up daily to S3(data repository) for disaster recovery
						- File System deployment options;
							1. Scratch File System : Temporary storage with high performance/burst (6x faster than Persistent, throughput of 200 MB per second per TiB)
								- Data is not replicated (doesn’t persist if file server fails)
								- Usage: short-term processing, optimize costs
							2. Persistent File System : Long-term storage with data replication within same AZ allowing failed files replacement within minutes
								- Usage: long-term processing, sensitive data
						- Two most important offerings
							1. FSx for Windows file server(for windows EC2 instances)
							2. FSx for Lustre (Linux + cluster)
							3. FSx for NetApp ONTAP 
							4. FSx for OpenZFS

			AMI(Amazon Machine Image) (Regional resource - copied across regions) e.g. Amazon Linux 2 AMI
				- provides the information required to launch/create ready to use EC2 instance with customization(can add software, configuration, os, monitoring tool, etc.)
				- Faster boot/configuration time because all softwares will be available pre-packaged on instance through AMI(custom instance launching instructions)
                - AMI must be in the same region as that of the Amazon EC2 instance to be launched, AMI can be copied to the region where you want to launch the EC2 instance
				- Allows recovery from Recycle Bin for AMI deletion(for accidental deletion) with specified retention period(from 1 day to 1 year)	
				- Allows creation of custom(Golden) AMIs by configuring an EC2 instance first(takes time) and then using Golden AMI to launch new instances quickly
				- unlike Bootstrap Script automation, Golden AMI is an image that contains all your software installed and configured so that future EC2 instances can boot up quickly from that AMI
				EC2 Image Builder : AWS service used to automatically and easily build, test & distribute own AMI rather than using public AMIs or AWS Marketplace AMI(buy-sell)

			ELB(Elastic Load Balancer)
				- AWS managed load balancer/load balancer instances that forward traffic to multiple EC2 instances(servers) optionally across multiple AZ
				- used to expose single point of access(DNS) to the application seamlessly handling failures 
                - Equipped with health check mechanism via port(4567) and a route(/health) by HTTP protocol expecting response 200:success response
                - Integration with target groups which are set of machines/servers from below AWS services
                    • AWS EC2, EC2 instances managed by Auto Scaling Groups, AWS ECS, AWS Lambda
                    • AWS Certificate Manager(ACM), private IP addresses
                    • AWS CloudWatch
                    • Route 53, AWS WAF, AWS Global Accelerator
				ELB Stickey Sessions(Session Affinity) 
					- To implement stickiness at target group level so that the same clients traffic is always redirected to the same instance behind a load balancer avoding re-logins requirements
					- for CLB, ALB with cookies having defined expiration duration, and Network Load Balancer	
						1. Application-based Cookies : cookies with application specified custom expiration duration(1sec to 7days)
							a. Custom cookie : generated by application with custom name(except AWSALB, AWSALBAPP, or AWSALBTG) specified individually for each target group
							b. Application cookie : generated by the load balancer with name is AWSALBAPP
						2. Duration-based Cookies : generated by the load balancer having load balancer specified expiration time with name is AWSALB for ALB, AWSELB for CLB
				ELB Cross-Zone Load Balancing
					ALB : Enabled by default(can be disabled at Target Group level), no additional charges for inter AZ data traffic
					NLB and GWLB : Disabled by default, can be enabled with extra charge for inter AZ data traffic
				- Connection Draining(for CLB)/Deregistering Delay(for ALB,NLB) : time to complete in-flight traffic while server/instance is de-registering or unhealthy
				- Types of ELB
                    0. Classic Load Balancer(HTTP/HTTPS/TCP/SSL(secure TCP)) : older generation(2009) load balancer
					1. Application Load Balancer(only HTTP/HTTPS/websocket/gRPC traffic, static DNS)(2016) : Layer 7(HTTP)
                        • manage traffic for multiple HTTP applications across target groups(set of machines; EC2 instances managed by ASG, ECS containers, Lambda Functions, private IP addresses) based on routing rules defined in routing table
                        • supports redirects(for example, from HTTP to HTTPS);
                        • Health Check supports HTTP and HTTPS protocol
						• IP receive in requests will be the ALB's private IP address; ALB adds an additional request header called "X-Forwarded-For" contains the client's IP address
						• provides a static DNS name but does NOT provide a static IP
                        • Great for micro services & container-based application(has a port mapping feature to redirect to dynamic port in ECS)
					2. Network Load Balancer(TCP/UDP/TLS(secure TCP) traffic)(2017) : Layer 4
                        • For ultra high performance requirements with ultra low latency
                        • provides both static DNS name & static IP per AZ and supports elastic IP assignment(helpful for whitelisting application with specific static IP) to each AZ
                        • Health Check supports TCP, HTTP and HTTPS protocol
						• Registered targets in a Target Groups for an Application Load Balancer can be ALBs too
					3. Gateway Load Balancer(Route traffic to firewalls, GWLB protocol)(2020) : Layer 3(Network Layer)
                        • To analyze traffic at network level via firewall, intrusion detection & prevention systems, deep packet inspection, payload manipulation, etc.
						• Inspect network traffic via 3rd party virtual appliances in target group before forwarding that to application
                            User [Route Table]      -->      Gateway Load Balancer      -->      Application
                                                                    ⇣   ⇡
                                                                Target Group
                                                    3rd Party Security Virtual Appliances
                                                    
			ASG(Auto Scale Group)
				- implement elasticity(auto scale out(increase count) and scale in(decrease count) based on demand) for application across multiple AZ with defined min-max count
				- integrates with ELB(automatically register new instances to load balancer) as well as replace unhealthy instances by using Load Balancer health check result
				- Free to use, but you have to pay underlying EC2 instances managed by ASG
				- Scaling using Scaling Policies & Launch Template(AMI + Instance Type + EC2 user data + EBS volume + SG + IAM roles + Network-Subnet config + Load Balancer)
					• Dynamic
						1. Simple/Step Scaling : according to CloudWatch alarm/alarms trigger(CPU > 70% -> add instance | CPU < 30% -> remove instance)
						2. Target Tracking Scaling : defined target avg CPU utilitization to stay around 60%
					• Scheduled : increase min/max capacity to 9AM to 12 AM on Sat-Sun
					• Predictive : uses ML to predict future traffic ahead of time
				- Metrics to scale in/out on CPU-utilization, Request count per target, Average Network In/Out, Any custom metric(captured using CloudWatch)
				- Scaling Cooldowns : As scaling activity happens, cooldown period(default 300 seconds) begins, stopping launch/terminate additional instances to allow for metrics to stabilize

			EC2 Pricing
				- Only charged for what you use
				- Number of instances
				- Instance configuration:
					• Physical capacity
					• Region
					• OS and software
					• Instance type
					• Instance size
				- ELB running time and amount of data processed by load balancer
				- Detailed monitoring(default freq is 5 min, we can set min 1 min freq, paying specified amount for that)


		AWS Lightsail
			- For someone that has no cloud experience and need to get started quickly without configuration need(unlike EC2, RDS, ELB, EBS)
			- Virtual private servers, SSD-based storage, databases, and networking(DNS management, static IP address) with low & predictable pricing
			- Has high availability but no auto-scaling, limited AWS integrations
			- Used to create a simple web application, a website or a dev/test environment


		AWS ECS(Elastic Container Service)
			- Launch Docker containers on AWS EC2 on-demand or spot instances pre-installed with ECS Agent(to register instance in ECS cluster)
			- Needs manual pre-provision & maintain the infrastructure(EC2 instances or On-premise servers)
			- Pricing; don't get any fees for using ECS, but have to pay for AWS resources stored and created in your application(ECS cluster)
			- IAM Roles for ECS;
				• EC2 Instance Profile : IAM role associated with an EC2 instance which is used by the ECS agent 
					- To Makes API calls to ECS service
					- Send container logs to CloudWatch Logs
					- Pull Docker image from ECR
					- Reference/Fetch sensitive data in Secrets Manager or SSM Parameter Store
				• ECS Task Role : IAM role defined in your ECS task definition
					- Allows each task to have a specific role to control what AWS resources your tasks can access
					- Use different roles for the different ECS Services you run
			- Has integrations with the Load Balancer(ALB & NLB to pair with AWS Private Link)
			- ECS Tasks ASG; Automatically increase/decrease the desired number of ECS tasks(using AWS Auto Scaling) based on
				• cpu/memory utilization
				• ALB request count per target
				• target value for a specific CloudWatch metric
				• specified CloudWatch Alarm
				• sheduled date/time
			ECS Cluster Capacity Provider
				- Automatically provision and scale the infrastructure(EC2 instances) for your ECS Tasks
			- ECS Service Auto Scaling(task level) ≠ EC2 Auto Scaling(EC2 instance level)
			- Allow mounting EFS file systems onto ECS tasks for persistent multi-AZ shared storage for your containers; S3 cannot be mounted as a file system
			- EventBridge allows to understand the lifecycle of containers in ECS cluster by sending/receving events
            AWS OpsWorks
                - Use Chef and Puppet(automation platforms that allow you to use code to automate the configurations of your servers) 
                - To automate how servers are configured, deployed, and managed across your Amazon Elastic Compute Cloud (Amazon EC2) instances or on-premises compute environments


		AWS Fargate
			- Launch Docker containers on AWS serverless
			- No need of provision the infrastructure (no EC2 instances to manage); Just need to define task definitions
			- AWS just runs containers for you based on the CPU/RAM you need
			- Has integrations with the Load Balancer(ALB & NLB to pair with AWS Private Link)
			- Allow mounting EFS file systems onto ECS tasks for persistent multi-AZ shared storage for your containers; S3 cannot be mounted as a file system
			- Pricing; Pay for vCPU and memory resources allocated to your applications in your containers


		ECR(Elastic Container Registry)
			- Private and Public(AWS ECR Public Gallery) Docker Registry(images repository) on AWS, fully integrated with ECS and leverages S3 storage for images
			- Storage of Docker container images allowing easy retrieval by ECS or Fargate
			- Supports Docker image vulnerability scanning, versioning, images tags, image lifecycle


		EKS(Elastic Kubernetes Service)
			- Allows you to launch managed Kubernetes(open-source system for management, deployment, and scaling of containerized apps) clusters on AWS
			- EKS pods(containers) running on EKS nodes(EC2 on-demand or spot instances)
			- For multiple regions, deploy one EKS cluster per region 
			- Collect logs and metrics using CloudWatch Container Insights
			- Use case: Migrate on-premises or another cloud Kubernetes cluster application to AWS
			- Containers can be hosted on:
				• EC2 instances(Managed Node Groups & Self-Managed Nodes)
				• Fargate(Serverless)
			- Data Volumes; by specifying StorageClass manifest on EKS cluster leveraging add-on Container Storage Interface(CSI) compliant driver supporting EBS, FSx(Luster, NetApp ONTAP), EFS(for Fargate)


		AWS App2Container(A2C)
			- CLI tool for Lift-and-shift migrating Java and .NET lagecy web apps running in on-premises, VMs, or in any Cloud to AWS Docker Containers
			- Generates CloudFormation templates(for compute, network, etc.), register generated docker containers to ECR then deploy to ECS, EKS, or App Runner
			- Supports pre-built CI/CD pipelines


		Lambda Container Image
			- The container image must implement the Lambda Runtime API
			- But, ECS/Fargate is always preferred and recommended for running any Docker images


		AWS Lambda(Function as a Service) Regional Resource
			- Serverless, on-demand(concurrent and independant execution), auto-scalable, event-driven(invoked by AWS as needed) & designed for short executions(max 15 min)
			- Easy to get more resources per functions(128 MB, up to 10GB of RAM) & Increasing RAM will also improve vCPU and network performance
			- Only have upto 4 KB of environment variable space, and additional emphoral(/tmp) disk space of 512 MB upto 10 GB
			- Default account limit of 1,000(negotiable) concurrent executions per all functions of region, recommended to use reserved concurrency(limits concurrent executions for a function)
			- Lambda function deployment size limits;
				• 50 MB for compressed .zip
				• 250 MB for Un-compressed code + dependencies 
				• <250 MB, /tmp directory can be used at startup
			- Lambda provides both synchronous & asynchronous invocations
				• Synchronous invocation
					- Caller waits for return response from lambda, used for Real-time APIs(API Gateway), sync workflows(Step Function)
					- Retries should be controlled by caller in case of error
				• Asynchronous invocation(background processing)
					- Caller invokes and moves on, used for Background tasks(S3 event notification), event triggers(SNS, EventBridge)
					- Retries(upto 2 more times) is controlled by AWS with configuration ability of dead-letter queues(DLQ) or Event Destinations
					- For throttling errors(429) and system errors(500-series), Lambda returns the event to internal event queue and re-run the function again for up to 6 hours
					- retry interval from internal event queue increases exponentially from 1 second after the first attempt to a maximum of 5 minutes
			- Cold Start
				• First request served by new instances has higher latency than the rest, especially in VPCs & if the init(code, dependencies, SDK loading) is large 
				• To avoid cold start
					- provisioned concurrency with Application Auto Scaling to adjust capacity based on traffic with minimum required target utilization to save cost
					- Avoid Unnecessary(if lambda doesn’t need to access private resources) VPC Configuration as due to ENI attachment, lambda in a VPC takes longer to start
			- Easy monitoring through AWS CloudWatch & sheduled trigger setup using CloudWatch Events EventBridge
			- Limited Runtimes - Node.js(JavaScript), Python, C#, Ruby, etc. as well as Custom Runtime API(community supported, example Rust or Golang) & containers image
			Lambda SnapStart
				- For new version published(Java, Python, .NET), lambda automatically initialize and snapshots memory, disk state and cached for low-latency access for function execution
			- By default, your Lambda function is launched in an AWS-owned VPC, blocking access to AWS resources in your VPC
				• to access AWS resources from your VPC; VPC ID, Subnets and Security Groups should be added on lambda to create an ENI in your subnets to access VPC resources
            AWS Step Function : build serverless visual workflow ro orchestrate lambda function
                - Features; sequencing, parallel functions, confitions, timeouts, error handling, etc.
			- Pricing : Pay per request and compute time
				• First 1,000,000 requests are free || $0.20 per 1,000,000 requests thereafter ($0.0000002 per request)
				• 400,000 GB-seconds of compute time per month for FREE || After that $1.00 for 600,000 GB-seconds
					that means, == 400,000 seconds if function is configured with 1GB RAM
								== 3,200,000 seconds if function is configured with 128 MB RAM


		AWS Glue(managed ETL)
			- Managed serverless extract(from s3/RDS), transform, and load(in RedShift for Analytics) (ETL) service
			- Useful to prepare and transform data for analytics
			- default timeout 2 days, max timeout 7 days
			- Glue Job Bookmarks : prevent re-processing old data
			• Glue DataBrew : pre-built transformation to clean and normalize data
			• Glue Studio : new GUI to create, run and monitor ETL jobs in Glue
			• Glue Streaming ETL(built on Apache Spark Structured Streaming) : compatible with Kinesis Data Streaming, Kafka, MSK (managed Kafka)
			AWS Glue Data Catalog
				- central repository to store(fetched by AWS Glue Data Crawler) structural and operational metadata for all your data assets to be used by Glue, Athena, EMR
				- For dataset, store its table definition, physical location, add business relevant attributes, as well as track how this data has changed over time


		AWS Batch
			- Fully managed(not serverless) scalable batch processing service without time/storage limit(unlike Lambda with 15 min and limited temporary disk space)
            - Allow to easily and efficiently run hundreds of thousands of batch computing jobs on AWS
			- Batch jobs are defined as Docker images and runs on ECS(EC2 instances or Spot Instances(cheapest EC2))
			- Runtime supports - as we are working on EC2 server this supports any runtime as long as it’s packaged as a Docker image(unlike Lambda with limited runtimes,py/node/java/etc.)
			- Batch will dynamically launch EC2 instances or Spot Instances with provisioning the right amount of compute/memory


		AWS API Gateway
			- Fully managed Serverless and scalable service to create, publish, maintain, monitor, and secure APIs
			- Supports RESTful APIs and WebSocket APIs with versioning, environments, security(user authentication/authorization), API throttling, API keys, monitoring
			- Transform and validate requests and responses with API responses caching
			- Swagger/Open API import/Export to quickly define APIs
			- Integration with;
				• Expose AWS service(Lambda functions) as HTTP API
				• Expose HTTP endpoints(internal HTTP API on premise, Application Load Balancer) for rate limiting, caching, user authentications, API keys, etc.
			- Allow HTTPS security through integration with AWS Certificate Manager(ACM)
				• If using Edge-Optimized endpoint, then the certificate must be in us-east-1
				• If using Regional endpoint, the certificate must be in the API Gateway region
				• Must setup CNAME or A-alias record in Route 53 to point to your domain and API Gateway
			- Endpoint Types;
				• Edge-Optimized (default) : still lives in only one region, but Requests are routed through the CloudFront Edge locations (improves latency)
				• Regional : for clients within same region, allowing manually combine with CloudFront to get more control over caching and distributing
				• Private : accessed(allow access in resource policy) only from your VPC using an interface VPC endpoint(ENI)
			Edge-Optimized API Gateway
				- API requests are routed to the nearest CloudFront Edge Location for geographically distributed clients which improves latency
				- The API Gateway still lives in one AWS Region.


		AWS App Runner
			- Fully managed service to deploy web app and APIs at scale just using source code/container image and configuarations(vCPU, RAM, Auto Scaling, Health Check)
			- Supports VPC access allowing connection to database, cache, and message queue services
			- Use cases: web apps, APIs, microservices, rapid production deployments


        AWS Step Function : 
            - build serverless visual workflow to orchestrate your function(generally Lambda)
            - Features; sequencing, parallel functions, conditions, timeouts, error handling, human authentication(approval like MFA, Capcha, want to continue button), etc.
            - can integrate with; EC2 instances, ECS, On-premises servers, API Gateway, SQS queues, etc.
            - use cases: order fulfillment, data processing, web applications, etc.


        AWS Ground Station (for users having own Satellites roaming around earth)
            - Managed service to control satellite communications(in the shortest possible time), process data & scale satellite opperations and send data to s3 or EC2 instance
            - use cases: weather forcasting, surface imaging, communications, video broadcasts




	Storage
		AWS S3(infinitely scaling serverless storage/Simple Storage Service)(Object/File level storage) (Regional resource)
			- Used for
				- Backup and storage
				- Disaster recovery(by storing on multiple regions)
				- Archive 
				- Hybrid Cloud Storage
				- Application Hosting
				- Media Hosting
				- Big Data Analytics
			- Automatically scales to high request rates(3,500 PUT/COPY/POST/DELETE or 5,500 GET/HEAD requests per second per prefix in a bucket), latency 100-200ms
			- If spread reads across four prefixes evenly, 22,000 requests per second for GET and HEAD can be achieved
			- S3 allows to store objects(files) in Buckets(directories)
				Bucket(directory)
					- Buckets have globally unique name across all regions and accounts even if bucket is actually only scoped to specific region
					- Bucket Naming convention
						- no uppercase letter
						- no '_'
						- 3-63 character long
						- should not be IP
						- must start with letter or number
						- must not start with prefix 'xn--' and not end with suffix '-s3alias'
				Prefix
					- Middle part of a bucket and key, used to simulate folders, filter files, or manage large datasets efficiently. e.g. bucket/folder1/sub1/file => /folder1/sub1/
				Object(files)
					- Consists of 
						Key(full path with filename)    eg. s3://my-bucket/my_file.txt
						Object Value
							- max object size is 5TB
							- if object is greater than 5GB, must use 'multi-part upload' for several parts
						Metadata(list of key-value pairs, set by system/user)
						Tags(Unicode key-value pair) 
							- max 10
							- useful for security/lifecycle
						Version Id(if versioning enabled)


			S3 Security
				User Based 
					IAM Policies - which API call should be allowed for a specific user from IAM
				Resource Based 
					Bucket Policies
						- to grant Public Access to bucket 
						- Force objects to be encrypted
						- allows cross account(IAM user in another AWS account)
					Object ACL(Access Control List) 
					Bucket ACL(Access Control List)
                        Note - any AWS for accessing s3 bucket need to be added allowed list in S3 Bucket Policies
				Encryption 
					- Encrypt objects using encryption keys
					- If we edit pre-encrypted object from versioning enabled bucket, new version of the object is created with updated setting and new last-modified date	
					1. Server side encryption with Amazon S3 managed keys(SSE) is ON by default(free to use), i.e. uploaded unencrypted object is going to be encrypted by AWS S3
						  • Amazon S3-Managed Keys (SSE-S3) : Encrypts(type AES-256) S3 objects using keys handled, managed, and owned by AWS. Users can't have access to these krys
						  • KMS Keys stored in AWS KMS (SSE-KMS) : Encryption using keys handled and managed by AWS KMS; user control + audit key usage using CloudTrail
							- KMS has limited API(GenerateDataKey(uploads),Decrypt(downloads)) call quota 5500-30000 req/s based on region(can be increased using Service Quotas Console)
						  • Customer-Provided Keys (SSE-C) : Managed by the customer outside of AWS(key does not stored on AWS); for every HTTP request made, encryption key must provided in headers
						  	- Only configured from CLI, not available from AWS console
					2. Client side encryption : clients encrypt sending/retrieving data to/from S3 managing keys and encryption cycle using client libraries(Amazon S3 Client-Side Encryption Library)
					3. In-transit(SSL/TLS) : mandatory for SSE-C
						- force in-transit encryption using bucket policy; Bucket Policies are evaluated before “Default Encryption”
				Monitoring - IAM Access Analyzer for S3
					- Ensures that only intended people have access to your S3 buckets which are publicly accessible bucket, bucket shared with other AWS accounts
					- Evaluates S3 Bucket Policies, S3 ACLs, S3 Access Point Policies
				CORS(Cross Origin Resource Sharing)
					- CORS is Web Browser based mechanism used to allow request to other origins while using the main origin
					- Main Origin = https://www.origin.com 
					- Other origin = https://www.cross-origin.com -> with CORS enabled for main Origin(setting COSR header "Access-Control-Allow-Origin": "https://www.origin.com")
					- If a client makes a cross-origin request on our S3 bucket, we need to enable the correct CORS headers for a specific origin or *(all origins).
					- CORS definition in S3 bucket of https://www.cross-origin.com ;
							[
								{
									"AllowedHeaders": [ "Authorization" ],
									"AllowedMethods": [ "GET" ],
									"AllowedOrigins": [ "https://www.origin.com" ],
									"ExposeHeaders": [],
									"MaxAgeSeconds": 3000
								}
							]
				MFA for operations
					- Re-authenticate users before doing operations(Permanently delete an object version, Suspend Versioning on the bucket) only on versioning enabled S3
					- Only bucket owner(root account) can enable/disable MFA
				Server Access Logs
					- Logs any request made to S3 from any account, authorized or denied into another S3 bucket in same AWS region for analysis using data analysis tool(Athena)
					- Never ever set same bucket for monitoring and logging, that would create an infinite loop and bucket grows exponentially 
				S3 presigned url 
					- signature token which has credentials encoded temporarily inheriting permissions(GET/PUT) of user that generated the URL for specific object in pvt bucket
					- generated-by(expiration time) : S3 Console(1min-12hrs), AWS CLI(default 1hr, max ~168 hrs) or SDK
				WORM (Write Once Read Many) model
					1. S3 Glacier Vault Lock
						- Create a vault lock policy(e.g. object deletion, etc.) with feature of locking the policy itself for future edits(changed or deleted)
					2. S3 Object Lock(Versioning Enabled Bucket)
						- Block an object version deletion for a specified fixed period, that can be extended
						- Retention mode : Compliance
							• Object versions can't be overwritten or deleted by any user, including the root user
							• Objects retention modes can't be changed, and retention periods can't be shortened
						- Retention mode : Governance
							• Most users can't overwrite or delete an object version or alter its lock settings
							• Some users have permissions(IAM) to change the retention or delete the object
						- Legal Hold:
							• protect the object indefinitely, independent from retention period
							• can be freely placed and removed using the s3:PutObjectLegalHold IAM permission
				Access Points
					- bucket policies can get complicated and hard to manage Many applications/users need different permissions and to restrict access only within your VPC(avoiding routing via internet)
					- Access Points are regional control layer with no additional charges for granular(prefix), flexible, and scalable control over users and apps access the same S3 bucket
					- Each access point has; 
						• DNS name.e.g. my-ap-1234567890.s3-accesspoint.region.amazonaws.com (Internet Origin or VPC Origin by creating VPC end-point) 
						• access point policy(similar to bucket policy) to manage security at scale
				S3 Object-Lambda
					- Transform or process data on-the-fly as it's being retrieved from S3 using Lambda functions
					- real-time data transformation layer over S3, using Lambda
						Client 		→ 		S3 Object Lambda Access Point 	→ 	Lambda Function		→ 	  Transformed Object Response
                             	   	    	              ↑
                             	   			original object from S3 bucket
					- Use Case; Redact PII in logs(strips out usernames/emails), Convert images to thumbnails, change format(JSON → CSV or XML → JSON)


				Note -     
					IAM users(Acc) -> IAM Policy
					EC2(services) -> IAM Role
					Cross-Account -> Bucket Policy

			S3 Versioning
				- versioning is for objects, but enabled at Bucket-Level
				- Easy rollback to "noncurrent versions"(versions older than latest version)
				- Avoid unintended deletion by creating hidden object(delete marker) allowing recovery
				- Files prior to enabling versioning will have version 'null'
				- Suspending(turning off) versioning doesn't delete previous versions

			S3 Replication
				- Versioning must be enabled as well as proper IAM Permissions should be given for both(source & target) buckets
				- Copying/replication happens asynchronous/background
                - Only new objects(with version) are replicated after you enable Replication. optionally, with additional cost replication of existing obj can be done using S3 Batch Replication
                - Deletion with VersionId(permanent deletes) are not replicated to avoid malicious deletes
                - there is not replication chaining. i.e. bkt A has replication into bkt B, which has replication to bkt C then objects of A are not replicated to C
				- Two types of replication:
					1. Cross-Region Replication(CRR)
                        Use Case;
						- compliance
                            - lower latency access(to other region user)

					2. Same-Region Replication(SRR)
                        Use Case;
                            - log aggregation across multiple S3 buckets
						- live replication between production and test accounts 

			S3 Storage Class
				- Can move between classes manually or using S3 Lifecycle configurations	
				- Durability:	Same for all storage classes
					• High durability (99.999999999%, 11 9’s) of objects across multiple AZ
					• If you store 10,000,000 objects with AWS S3, you can on average expect to incur a loss of a single object once every 10,000 years
				- Availability:	Varies depending on storage class
					• Measures how readily available a service is
					• Example: S3 standard object has 99.99% availability. i.e. not available 53 minutes a year(accessing object will give random error)
				- Storage classes(with permitted object movement between them):
				 ⬇	1. Standard - General Purpose
			 	 ⬇		- Object has 99.99% availability
				 ⬇		- User for low latency frequently accessed data
				 ⬇		- sustain the concurrent loss of data.
				  ↘				i.e. data is recoverable even if multiple physical locations experience simultaneous failures (e.g., natural disasters, power outages)
				 ⬇	2. Standard-Infrequent Access (IA)
				 ⬇		- data that is less frequently accessed, but requires rapid access when needed
				 ⬇		- Lower cost than S3 Standard for storage & will cost on data retrieval therefore use case is disaster recovery, back-ups
				  ↘		- Object has 99.99% availability
				 ⬇	3. Intelligent Tiering
				 ⬇		- Small monthly monitoring and auto-tiering fee to moves objects automatically between Access Tiers based on usage
				 ⬇		- There are no retrieval charges in S3 Intelligent-Tiering
				 ⬇		• Frequent Access tier (automatic): 		default tier
				 ⬇		• Infrequent Access tier (automatic): 		objects not accessed for 30 days
				 ⬇		• Archive Instant Access tier (automatic): 	objects not accessed for 90 days
				 ⬇		• Archive Access tier (optional): 			configurable from 90 days to 700+ days
				  ↘		• Deep Archive Access tier (optional): 		configurable from 180 days to 700+ days
				 ⬇	4. One Zone-Infrequent Access (IZ-IA)
				 ⬇		- data that is less frequently accessed, but requires rapid access when needed
				 ⬇		- Lower cost than S3 Standard for storage & will cost on data retrieval.
				 ⬇		- Data lost when AZ is destoryed where data was stored
				 ⬇		- Object has 99.5% availability(99.99% in single AZ)
				  ↘		- Use Cases: Storing secondary backup copies of on-premise data, or data you can easily recreate like thumbnails
				 ⬇	5. Glacier Instant Retrieval
				 ⬇		- Low-cost object storage meant for archiving/backup with pricing for storage + object retrieval cost
				 ⬇		- Millisecond Retrieval, great for data accessed once a quarter
				  ↘		- Minimum storage duration of 90 days. i.e. duration that you pay for the service even if you don't utilize it for the entire 90 days
				 ⬇	6. Glacier Flexible Retrieval
				 ⬇		- Low-cost object storage meant for archiving/backup with pricing for storage + object retrieval cost
				 ⬇		- Retrieval : Expedited (1 to 5 minutes), Standard (3 to 5 hours), Bulk (5 to 12 hours) - free
				  ↘		- Minimum storage duration of 90 days
				  	7. Glacier Deep Archive - for long term storage and is cheapest
						- Low-cost object storage meant for archiving/backup with pricing for storage + object retrieval cost
						- Retrieval : Standard (12 hours), Bulk (48 hours)
						- Minimum storage duration of 180 days
                    
                    8. S3 Express One Zone - for Directory Bucket
                        - 10x better performance(1,00,000 req/sec) than S3 Standard with 50% lower cost, but single AZ 
                        - Easy integration with Sagemaker, Athena, EMR, Glue, etc. for Latency sensitive apps, AI-ML apps, HPC, media processing, etc.

            S3 Lifecycle Rules
                - shedule objects to change storage classes based on multiple Transition/Expiration(delete) Actions specified(prefix, tags, duration of storage, etc.)
                - In-case of multiple lifecycle rules defined, first one to execute takes priority
				- Move/expire/permanently-delete current/noncurrent/delete-markers/incomplete-multipart-upload versions between storage classes
				- S3 Analytics to analyze storage access patterns to make smart decisions about moving infrequently accessed data to cheaper storage classes like S3 Standard-IA
					• Not supported for; One-Zone IA or Glacier

			S3 Pricing;
				- Storage class: S3 Standard, S3 Infrequent Access, S3 One-Zone IA, S3 Intelligent Tiering, S3 Glacier and S3 Glacier Deep Archive
				- Based on storage volume(Number and size of objects) 
				- Number and type of requests(S3 Requester Pays feture; to charge Data transfer and request costs from the verified requester’s AWS account)
				- Data transfer OUT of the S3 region(transfer IN S3 is free)
				- S3 Transfer Acceleration
				- Lifecycle transitions

			S3 Event Notification
				- Automatically trigger actions for certain events(uploads, deletes, restoration) & send an event notification to SQS, Lambda, SNS or EventBridge
				- With EventBridge, we can write multiple rules, each with custom logic and different targets — all from the same S3 event stream

			S3 Performance
				1. Multi-Part upload
					- Parallelize uploads speeding up transfers; recommended for files size > 100MB, must use for files size > 5GB
				2. S3 Transfer Acceleration
					- Increase global transfer speed by transferring file to an AWS edge location which will forward the data to the S3 bucket in the target region
					- File in USA   ==(public WWW)==>   Edge Location in USA   ==(private AWS)==>   S3 Bucket in Asia
					- Compatible with multi-part upload
				3. S3 Byte-Range Fetches
					- Parallelize GETs/downloads by requesting specific byte ranges
					- Better resilience in case of failures, in-case you have a failure to get a specific byte range, then you can retry a smaller byte range
					- Can be used to retrieve only partial data (for example the head of a file)

			S3 Batch Operations
				- Perform bulk operations on existing S3 objects(queried/filterd by Athena on S3 Inventory given object list) with a single request 
				- Manages retries, tracks progress, sends completion notifications & generate reports
				- for example:
					• Modify object metadata & properties
					• Copy objects between S3 buckets
					• Encrypt un-encrypted objects
					• Modify ACLs, tags
					• Restore objects from S3 Glacier
					• Invoke Lambda function to perform custom action on each object

			S3 Lens 
				- Understand, analyze, and optimize storage across entire AWS Organization(multiple accounts, regions, buckets) to generate aggregated metrics reports and un-erasable(can be disabled) dashboards
				- Metrics;
					Free Metrics
						• Automatically available for all customers
						• Contains around 28 usage metrics
						• Data is available for queries for 14 days
					Advanced Metrics and Recommendations
						• Get additional paid advanced metrics(Activity, Advanced Cost Optimization, Advanced Data Protection, Status Code) and features
						• CloudWatch Publishing - To access metrics without additional charges
						• Prefix Aggregation - Collect metrics at the prefix level
						• Data is available for queries for 15 months
				- Used to discover anomalies, identify cost efficiencies, and apply data protection best practices across entire AWS Organization(captures 30 days usage & activity metrics)


		AWS Snow Family 
			- Highly-secure, portable devices to collect and process data at the edge location, and migrate data into and out of AWS
			- To perform petabytes data migrations(import data onto S3)/Edge Computing using rented physical device
			- Edge location may refers to truck on the road, a ship on the sea, a mining station underground which have limited internet and no access to computing power
			- types:
				1. Snowcone : 2 CPUs, 4 GB of memory, wired or wireless access with 8 TB HDD - 14 TB SSD storage capacity
					- AWS Snowcone is a small, portable, rugged, and secure edge computing and data transfer(with pre-installed DataSync Agent) device
					- Provides up to 8 TB of usable storage. Despite proving local computing capacity, it is not best-suited for petabytes-scale transfers
				2. Snowball Edge  
					a. Compute Optimized(dedicated for use case) : powerful local computing resources for higher performance workloads, not suited for data transfer
					b. Storage Optimized : with storage capacity Up to petabytes(PB), local computing with higher storage capacity(210 TB) needs
				3. SnowMobile : Exabyte-scale data transfer service to move extremely large data to AWS. Not cost-effective for regular transfers of petabytes and doesn't provide local computing capacity.
			- OpsHub : desktop application to manage Snow Family devices
			- Pricing : only billed for device(Snowcone/Snowball Edge) rent(per days) excluding delivery/shipping days and data transfer-out of AWS(S3)


		AWS FSx(File System x)
			- Fully managed third-party file system service optimized for high-performance file systems with Multi-AZ feture on AWS 
			- Allowing to be accessed from On-premises infrastructure(VPN or Dorect Connect)
			- Data is backed-up daily to S3(data repository) for disaster recovery
			- File System deployment options;
				1. Scratch File System
					- Temporary storage with high performance/burst (6x faster than Persistent, throughput of 200 MB per second per TiB)
					- Data is not replicated (doesn’t persist if file server fails)
					- Usage: short-term processing, optimize costs
				2. Persistent File System
					- Long-term storage
					- Data is replicated within same AZ allowing failed files replacement within minutes
					- Usage: long-term processing, sensitive data
			- Two most important offerings
				1. FSx for Windows file server(for windows EC2 instances)
					- supports windows NTFS and SMB protocol(to access externally)
					- integration with MicroSoft Active Directory, Access Control List, user quotas for user security
					- Allow mounting on Linux EC2 Instances as well as supports on-premises FS using Microsoft's Distributed File System Namespace to group FSs together
					- scale up to 10 GB/s, millions of IOPS, 100 PB of data with SSD/HDD storage options
				2. FSx for Lustre (Linux + cluster)
					- Parallel distributed POSIX compliant file system with scalable file storage for High Performance Computing
					- scale up to 100 GB/s, millions of IOPS, sub-ms latencies
					- Provides seamless integration with S3, allowing reads and write to S3 through FSx.
				3. FSx for NetApp ONTAP
					- File System compatible with NFS, SMB, iSCSI protocol; generally to migrate workloads running on ONTAP/NAS to AWS
					- High OS compatibility; Linux, Windows, Mac-OS, VMware Cloud on AWS, Amazon Workspaces & AppStream 2.0, EC2, ECS and EKS
					- Allows low-cost snapshots, replication, compression and data de-duplication
					- Allows Point-in-time instantaneous cloning; helpful for testing new workloads
				4. FSx for OpenZFS
					- File System compatible with multiple versions of NFS( v3, v4, v4.1, v4.2), generally to migrate workloads running on ZFS to AWS
					- Best performance; Up to 1,000,000 IOPS with < 0.5 ms latency
					- Works with; Linux, Windows, MacOS, VMware Cloud on AWS, Amazon Workspaces & AppStream 2.0, EC2, ECS and EKS
					- Allows low-cost snapshots, replication, compression
					- Allows Point-in-time instantaneous cloning; helpful for testing new workloads


		AWS Storage Gateway
			- Hybrid Cloud storage; allows seamlessly integration of on-premises IT environment with AWS S3(cloud-based object storage service, not a traditional file system like EFS or NFS)
			- Integrates using Gateway set-up on clients data center or Amazons provided Storage Gateway Hardware Appliance including CPU, memory, network, SSD cache resources 
			- Types;
				• File Gateway
					1. S3 File Gateway
								Corporate Data Center									 AWS Cloud
						Application						S3 File
						Server 	  <------------->  	Gateway	  <----------HTTPS--------->		S3(Supports; S3 Standard, S3 Standard IA, S3 One Zone A, S3 Intelligent)
										NFS or 					 Encryption in Transit					Possible to send in S3 Glacier using S3 Lifecycle Policy
									SMB(with AD allowing 	 using Internet/Direct Connect
									user authentication)
					2. FSx File Gateway
						- FSx provides access to Windows File Server natively without need of FSx File Gateway as long as we not reqire local cache(low latency) for frequently accessed data
						- Windows native compatibility(SMB, NTFS, Microsoft AD, etc.)
						- Usecase; group file shares and home directories
				• Volume Gateway
					- Block storage using iSCSI protocol leveraging S3 with point-in-time backups as EBS snapshots
					- Two Types;
						1. Cached volumes: low latency access to most recent data cached
						2. Stored volumes: entire dataset is on-premise, scheduled backups to S3
				• Tape Gateway
					- Virtual Tape Library(VTL) leveraging Amazon S3 and S3 Glacier
					- Back up data using existing tape-based processes (and iSCSI interface)
			- Use Cases;
				• Extend on-premises(frequently accessed data) storage to AWS S3(infrequently accessed data)
				• Caching data on-premise for low-latency access
			- Data transferred between the storage gateway and AWS storage is encrypted using SSL (for all three types of gateways - File, Volume and Tape Gateways)


		AWS Transfer Family
			- Managed mulTi-AZ service for file transfers to/from AWS S3/EFS using the file transfer protocols(FTP(within VPC as no in-flight encryption), FTPS(SSL), SFTP)
			- Store and manage users’ credentials within the service or integrate with existing user authentication systems(Microsoft AD, LDAP, Amazon Cognito, custom)
			- Pricing; Pay per provisioned endpoint per hour + data transfers(in & out) in GB




	DataBase (worloads with indexing and quering capability needs)
		Relational Database	: tables(row + column)
			AWS RDS(Relational Database Service) 
				- Best for OLTP(Online Transaction Processing) and Joins
				- RDS database engines support; Postgres, MySQL, MariaDB, Oracle, Microsoft SQL Server, IBM DB2, AWS Aurora
				- AWS managed service with automated provisioning(vertical and horizontal scaling), optional backups(5 min freq, max 35 days retention) and restorable to specific point timestamp(5 min - 35 days)
				- Storage leveraging EBS(as AWS managed DB also hosted on EC2 instance), with automatic storage scaling upto defined max storage threshold
                - IAM Authentication(for DB connection), Security Groups(to control network access to DB), private proxy(middleman of application and DB, Improving database efficiency)
                - Encryption
                    • at-rest : Must be defined as launch time. if not, need to go through DB snapshot & restore as encrypted. unencrypted masters read replica cannot be encrypted
                    • In-flight : TLS-ready by default, use the AWS TLS root certificates client-side
				- Snapshot(AZ specific resource - using snapshot(back-up) & restore we can share, copy data to another region)
				- Allows restoration of on-premises database from S3 into new RDS instance running MySQL
				- can’t SSH into your underlying instances hosting RDS(except RDS Custom), unlike manually using EC2 instance used to host DB
				RDS Custom
					- Managed Oracle and Microsoft SQL Server Database with additional(including RDS) features having full admin access to the underlying OS and the database
					- Access to;
						• OS patches installation
						• DB customization
						• Native DB features
						• SSH or SSM Session Manager into underlying EC2 Instance hosting DB
					- Strongly recommended to take DB snapshots as access of underlying H/W also results in accidental breaking configuration. And de-activate RDS "Automation Mode" before performing customization
				- Read Replication
					• Up to 15 Read Replicas Within AZ, Cross AZ or Cross Region
					• Replication is ASYNC in same AZ(Synchronous in Multi-AZ), so reads are eventually consistent with zero-downtime
					• Replicas can be promoted to their own DB
					Same AZ - read replicas can be created to scale the read workload, data write only to main DB
					Multi AZ - One DNS name both for main and failover DB(standby/emergency DB copy) used in case of main DB AZ outage. But, only have 1 other AZ as db failover
					Multi Region - Disaster recovery for region with best all region read performance requiring multi-region replication cost
				- Pricing;
					• Per hour billing
					• Database characteristics/models:
						- Engine
						- Size
						- Memory class
					• Purchase type:
						- On-demand
						- Reserved instances (1 or 3 years) with optional up-front
					• Backup Storage: There is no additional charge for backup storage up to 100% of your total database storage for a region
					• Read Replication : 
						- free for same Region but different AZs replication(asynchronous data syncing from main DB to replica DB)
						- cost associated for different Region replication(asynchronous data syncing from main DB to replica DB) 
					• Additional storage (per GB per month)
						- for the underlying storage based on the EBS volume that you provision for your RDS database
					• Number of input and output requests per month
					• Deployment type(storage and I/O are variable)
						- Single AZ
						- Multiple AZs
					• Data transfer:
						- Outbound data transfer are tiered for volume discounts
						- Inbound is free
				- For stopped RDS database, user still have to pay for storage. Therefore instead of stopping unsable RDS-DB user should snapshot(cheaper) & restore as/when required
				- RDS Proxy(only privately accessible in VPC); especially for Lambda function deployed in your VPC directly accessing RDS in Private Subnet of same VPC


			AWS Aurora (RDS Aurora)
				- Best for OLTP(Online Transaction Processing) and joins
				- AWS cloud optimized Proprietary database with MySQL and PostgreSQL support
				- Aurora is made for high availability, store 6 copies of the data across 3 AZ anytime data is written with Self Healing(with peer-to-peer replication)
				- Storage grows automatically in increment of 10 GB, upto 128 TB, And storage is striped across 100s of volumes(EBS) supporting any point in time recovery
				- Cost 20% more than RDS, but more efficient(cost effective) for cloud. Not available in free tier
				- Max 15 cross region read replicas(excluding main/master DB) with faster auto scaling read replica as well as any of these read replica automatically becomes failover(instantly) in-case main DB fails
				- Uses Writer Endpoint(Pointing to the master) & Reader Endpoint(Connection Load Balancing) at connection level suitable for replicas auto scaling and instant main DB failover
				- Allows Custom Endpoints to define a subset of Aurora read instances to handle read traffic
				- On top of snapshots(back-up) and restores, Aurora offers faster DB cloning by sharing the same data volume(no data movement) and storing thereafter changes separately
				- Automated back-up max retention period is 35 days, Allows on-demand back-up for long-term backup storage for disaster recovery or audit purpose
				- For restoration of on-premises database from S3 into new RDS instance running MySQL, backup of on-premises database should be taken using "Percona XtraBackup"
                - IAM Authentication(for DB connection), Security Groups(to control network access to DB), private proxy(middleman of application and DB, Improving database efficiency)
                - Encryption
                    • at-rest : Must be defined as launch time. if not, need to go through DB snapshot & restore as encrypted. unencrypted masters read replica cannot be encrypted
                    • In-flight : TLS-ready by default, use the AWS TLS root certificates client-side
				Aurora Serverless
					- Automated database instantiation(process of creating a new instance of a class) and auto-scaling based on actual usage which provides least management overhead
					- Pay per second, can be more cost-effective
					- Use cases: good for infrequent, intermittent or unpredictable workloads
				Aurora Global DataBase
					- 1 Primary Region(read/write)
					- Up to 5 secondary(read-only) regions, And max 16 Read Replicas per secondary region
					- Cross-region replication takes less than 1 second
					- disaster recovery has an RTO of < 1 minute
				Aurora ML
					- Enables you to add ML-based predictions to your applications via SQL
					- Simple, optimized, and secure integration between Aurora and AWS ML services; Amazon SageMaker(use with any ML model), Amazon Comprehend(for sentiment analysis)
					- Use cases: fraud detection, ads targeting, sentiment analysis, product recommendations
				Babelfish for Aurora PostgreSQL
					- Allows Aurora PostgreSQL to translate commands(in T-SQL) targeted for MS SQL Server, therefore Microsoft SQL Server based applications can work on Aurora PostgreSQL
					- The same applications can be used after a migration of your database(using AWS SCT and DMS)
			Note - Invoke Lambda functions from DB(RDS/Aurora) instance(not configurable using AWS console), for successful registration welcoming email sending, etc.
				 - By allowing outbound traffic from DB(Public, NAT GW, VPC Endpoints) and invoking permission(Lambda Resource-based Policy & IAM Policy) for Lambda



		NoSQL Database : key-value(JS Object Notation), document, graph, in-memory, search database
			AWS DynamoDB(NoSQL ~Json)
				- Fully Managed NoSQL(key/value) distributed serverless DB
				- Highly available(Millions of requests per seconds, trillions of row, 100s of TB of storage) with replication across 3 AZ
				- Integrated with IAM for security, authorization and administration
				- low cost and auto scaling capabilities with Standard & Infrequent Access (IA) Table Class for cost saving
				- Table consists of Key-values;
					• Primary key(Partition[mandatory] and/or Sort Key)
					• zero(null) or more Attributes without need of any defined schema(i.e. schema is defined per item)
					• Maximum size of an item is 400 KB
					• Data Types;
						- Scalar Types : String, Number, Binary, Boolean, Null
						- Document Types : List, Map
						- Set Types : String Set, Number Set, Binary Set
				- Capacity Modes;
					• Provisioned Mode(default) : Manage and optimize costs by allocating Read & Write Capacity Units(RCU/WCU) in advance but comparatively slow scalling than on-demand
					• On-Demand Mode : Read/writes automatically swiftly scale up/down with your workloads with no capacity planning, 2x-3x more expensive than provisioned
				- Stream Processing : process task on stream of item-level modifications(create/update/delete) in a table
					• DynamoDB Streams
						- 24 hours retention with limited number of consumers support
						- Process using AWS Lambda Triggers or EC2 instace(using DynamoDB Stream Kinesis adapter)
					• Kinesis Data Streams
						- 1 year retention with high number of consumers support
						- Intefrate with AWS Lambda, Redshift(analytics), s3(archiving), OpenSearch(indexing), AWS Glue Streaming ETL,  etc.
				- Replication
					• DynamoDB Global Tables : replicate data automatically across Regions for distributed applications low latency read-write, must enable DynamoDB Streams
					• accessible with low latency in multiple-regions
					• Active-Active(2-way) replication (read/write to any AWS Region)
				- Backups for disaster recovery : Recovery process creates a new table
					• Continuous backups using point-in-time recovery (PITR)
						- Optionally enabled for the last 35 days
						- Allows exporting/importing table to/from S3(without consuming any read/write capacity) allowing querying using Athena engine
					• On-demand backups
						- Full backups for long-term retention, until explicitely deleted without affecting performance or latency
						- Can be configured and better managed in AWS Backup(enables cross-region copy)
				- Time To Live(TTL) for DynamoDB item : Automatically delete items after an expiry timestamp, generally ussed for web session handling
				- Allows capturing time-ordered sequence of item-level modifications in a DynamoDB table to create triggers to events in real-time only for AWS Lambda
				DynamoDB Accelerator - DAX Cluster
					- Fully Managed in-memory cached only for DynamoDB(different than ElastiCache which can be used for DynamoDB for storage of big-computation)
					- 10x performance improvement
					- default TTL of 5 mins, can be changed


			AWS ElastiCache(key-value pairs)
				- Managed in-memory caching capability Redis(highly available read replica) or Memcached(multi-node(sharded), best for multi-threading performance) for any(Relational/NoSQL) database
				- high performance, low latency, user login session data management, reduce load out off databases for read intensive workloads
                - Allows on-premise to create ElastiCache instances on an AWS Outpost
                - IAM authentication for Redis(not ElastiCache) + Redis Auth(password/token with SSL in-flight encryption) implementing extra security
                - ElastiCache Redis Sorted Set gurarantees both uniqueness and ordering(Each time a new element added, it’s ranked in real time, then added in correct order)
			
			
			AWS DocumentDB(For MongoDB)
				- AWS cloud optimized Proprietary database with MongoDB(NoSQL) support
				- Fully Managed, highly available with replication across 3 AZ
				- Automatically Storage grows in increments of 10GB and workloads scales with millions of requests per seconds


			AWS Keyspaces(for Apache Cassandra)
				- managed(traffic based auto scale tables up/down) Apache Cassandra-compatible(Cassandra Query Language) Serverless database service
				- Use cases: store IoT devices info, time-series data


			AWS Neptune(Graph Database)
			 	- Fully managed graph database (graph dataset are highly connected like a social network; Users, Posts, Comments, likes from users, Users post shares, etc.)
				- Optimized for complex and hard queries for highly connected dataset
				- Store up to billions of relations


			AWS Timestream(TimeSeries Database)
				- Fully managed, fast, auto scalable(up/down to adjust capacity), serverless time series database
				- Store and analyze trillions of events per day
				- 1000s times faster & 1/10th the cost of relational databases
				- Built-in time series analytics functions (helps you identify patterns in your data in near real-time)


			AWS QLDB(Quantum Ledger Database)
				- Immutable system: cryptographically verifiable entries to restrict removal or modification of entries of transactions(financial)
				- 2-3x better performance than common ledger blockchain frameworks
				- Ability to manipulate data using SQL
				- Centralized(unlike decentralized Amazon Managed Blockchain)


			AWS Managed Blockchain(decentralized)
				- Build applications where multiple parties can execute transactions without the need for a trusted, central authority.
				- To Join public blockchain networks or create your own scalable private network
				- Managed Hyperledger Fabric & Ethereum blockchain



		Big Data, Data Processing
			AWS Redshift(OLAP)
				- PostgreSQL based, OLAP(Online Analytical Processing and data Warehousing) database
				- Load data once every hour(not every second) with 10x better performance than other data warehouses, scale to PBs of data
				- Columnar storage of data (instead of row based)
				- Massively Parallel Query Execution (MPP), highly available
				- BI tools integration such as AWS Quicksight or Tableau to create dashboard on top of the availables data
				AWS Redshift Serverless
					- AWS managed provisions and scales data warehouse underlying capacity
					- Run analytics workloads without managing data warehouse infrastructure
					- Pay only for compute and storage used during analysis
					- Use cases: Reporting, dashboarding applications, real-time analytics, etc.


			AWS EMR(Elastic MapReduce)
				- Used to creating Hadoop clusters(can be made of hundreds of EC2 instances) to analyze and process vast amount of data
				- Supports Apache Spark, HBase, Presto, Flink, etc.
				- EMR takes care of all the provisioning and configuration
				- Auto-scaling and integrated with Spot instances
				- Use cases: data processing, machine learning, web indexing, big data, etc.


			AWS Athena(S3 data)
				- analyze data stored in S3 using serverless SQL to query the files
				- Supports CSV, JSON, ORC, Avro, and Parquet (built on Presto)
				- Pricing: $5.00 per TB of data scanned
				- Use compressed or columnar data for cost-savings (less scan)
				- Use cases: Business-intelligence/analytics/reporting, analyze & query VPC Flow Logs, ELB Logs, CloudTrail trails, etc.


			AWS QuickSight
				- Serverless machine learning-powered business-intelligence service to create interactive dashboards(published shareable read-only snapshots) out of data
				- Fast, automatically scalable, embeddable, with per-session pricing
				- Use cases:
					• Business analytics
					• Building visualizations
					• Perform ad-hoc analysis
					• Get business insights using data
				- Integrated with RDS, Aurora, Athena, Redshift, S3, and many 3rd party SaaS(Jira, Salesforce, etc.) or on-premise dataBase, etc.
				- In-memory computation using SPICE engine if data is imported into QuickSight(csv, excel, json, tsv) rather than using external data source(RDS)
				- Allow management of QuickSight specific users(standard version) & user groups(enterprise version) for dashboards to share with, not IAM users	 
				- provieds Enterprise edition of QuickSight which allows to setup Column-Level security(CLS), i.e. show/hide partial visuals to users based on users & user groups




		Search Optimization
			OpenSearch (JSON)
				- Free Text, unstructured Searches



		AWS DMS(Database Migration Service)
			- The source database remains available during the migration




	Disaster Recovery 
		• Strategies
			- Backup & Restore : Slowest but cheapest
			- Pilot Light : Only the most essential parts of your system are running in the cloud. You can quickly turn on the rest when needed
			- Warm Standby : Scaled-down version of your full system is always running in the cloud, ready to scale. Faster recovery than pilot light, more expensive
			- Multi-site/Hot-site : A full, identical copy of your system is constantly running in the cloud. Instant failover, fastest recovery, but most expensive


		AWS Elastic Disaster Recovery (DRS)
			- Quickly and easily recover your physical, virtual, and cloud-based servers into AWS
			    Example: protect your most critical databases(including Oracle, MySQL, and SQL Server), enterprise apps(SAP), protect your data from ransomware attacks, etc.
			- Continuous block-level replication using AWS replication agent(small program) for your servers from your corporate data center into the cloud


		AWS Backup
			- Fully-managed service to centrally manage On-demand and automate/scheduled backup across AWS services
			- Supports PITR(Point-in-time Recovery)
			- Ability to set frequency, Retention Periods, Lifecycle Management, Backup Policies, etc. for backups
			- Allows Cross-Region & cross-Account(using AWS Organizations) Backup




	Machine Learning Services
		AWS Rekognition
			- face detection/recognition, labeling, text detection, content(images and videos) moderation to create database out of captured information. e.g.familiar faces
            - Detect content that is inappropriate, unwanted, or offensive based on defined confidence threshold for items
            - Flag sensitive content for manual review in AWS Augmented AI(A2I)


		AWS Transcribe
			- audio to text(eg. subtitles) using DL auto speech recognition


		AWS Polly
			- text to audio


		AWS Translate
			- language translation. 
            - Uses neural machine translation via deep learning models to deliver more accurate and more natural-sounding translation than traditional statistical and rule-based translation algorithms


		AWS Lex
			- build conversational bots(eg. chatbots)
			- Service for building conversational interfaces into any application using voice and text. 
			- Provides the advanced deep learning functionalities of automatic speech recognition(ASR) for natural language understanding(NLU) to recognize the intent of the text
			- To enable you to build applications with highly engaging user experiences and lifelike conversational interactions


		AWS Connect
			- cloud contact center


		AWS Comprehend
			- natural language processing(NLP) service that uses machine learning to find meaning and insights in text


		AWS SageMaker
			- ability to build, train, and deploy machine learning (ML) models quickly for every developer and data scientist


		AWS Kendra
			- ML-powered search engine


		AWS Personalize
			- real-time personalized recommendations


		AWS Textract
			- detect text and data in documents


		AWS Forecasts
			- Fully managed service that uses machine learning to deliver highly accurate forecasts




	Other AWS Services
		AWS IoT Core
			- Allows to easily connect IoT devices(Network of internet-connected devices that are able to collect and transfer data) to the AWS Cloud
			- Serverless, secure & scalable to billions of devices and trillions of messages
			- Applications can communicate with IoT devices even when they are not connected
			- Integrates with a lot of AWS services(Lambda, S3, SageMaker, etc.)
			- Build IoT applications that gather, process, analyze, and act on data


		Amazon Elastic Transcoder
			- Elastic Transcoder is used to convert media files stored in S3 into media files in the formats required by consumer playback devices(phones etc.)
			- Benefits:
				• Highly scalable : Handle large volumes of media files and large file sizes with optimum processing power
				• Cost effective : running duration-based pricing model
				• Fully managed & secure, pay for what you use, where alternate way of transcoding in EC2 requires more money


		AWS Device Farm
			- Fully-managed service that tests your web and mobile apps concurrently on multiple devices(desktop browsers, real mobile devices, and tablets)
			- Also gives ability to configure device settings(GPS, language, Wi-Fi, Bluetooth, etc.)


        AWS AppFlow
            - Fully managed integration service to securely transfer data between SAAS applications(Salesforce, SAP, Zendesk, Slack, ServiceNow) and AWS(S3, Redshift) or non-AWS(SnowFlake, Salesforce)
            - Frequency: on a schedule, in response to events, or on demand
            - Data transformation capabilities like filtering and validation
            - Encrypted over the public internet or privately over AWS PrivateLinks
            - Use case is to without spend time writing the integrations by directly leverage APIs immediately


        Instance Scheduler on AWS (not a service)
            - AWS solution deployed through CloudFormation
            - Automatically start/stop your AWS services to reduce costs (up to 70%)
            - Example: stop company’s EC2 instances outside business hours
            - Supports EC2 instances, EC2 Auto Scaling Groups, and RDS instances
            - Schedules are managed in a DynamoDB table
            - Uses resources’ tags and Lambda to stop/start instances
            - Supports cross-account and cross-region resources
